{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Distributions\n",
    "## The Sampling Distribution of a Sample Mean\n",
    "**statistic** is a number that describes some characteristic of a **sample**. The value of a statistic can be computed directly from the sample data. We often use a statistic to estimate an unknown parameter. \n",
    "\n",
    "**parameter** is a number that describes some characteristic of the **population**. In statistical practice, the value of a parameter is not known because we cannot examine the entire population. \n",
    "\n",
    "$\\dagger$  \n",
    "A statistic is the estimator, as a random variable, of the unknown parameter.\n",
    "\n",
    "Let $\\mu$ and $\\sigma$ be the *mean* and *standard Deviation* of the *population* respectively. Then we have the relationship between the *sample mean* $\\bar{X}$ and them as following:\n",
    "1. $E\\big(\\bar{X}\\big) = \\mu$, thus an unbiased estimator of $\\mu$.\n",
    "2. $\\sigma_{\\bar{X}}^2 = \\sigma^2 \\big( \\bar{X} \\big) = \\displaystyle \\frac{\\sigma^2} {n}$, smaller than the parameter $\\sigma^2$, biased.\n",
    "3. Standard Deviation or Standard Error (SE): $\\sigma_{\\bar{X}} = \\sigma \\big( \\bar{X} \\big) = \\displaystyle \\frac{\\sigma} {\\sqrt{n}}$.\n",
    "\n",
    "**Central Limit Theorem** (CLT): For ***sufficiently*** large sample size $n$, $\\bar{X} \\sim \\DeclareMathOperator*{\\N}{N} \\N\\Big(\\mu, \\displaystyle\\frac{\\sigma} {\\sqrt{n}}\\Big)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Distributions for \"Counts\" and \"Proportions\"\n",
    "### Bernoulli Random Variable\n",
    "$X$ is a **Bernoulli random variable** with parameter $p$.\n",
    "1. **State Space**: $\\{0,1\\}$\n",
    "2. **Distribution func**: $P(X = 1) = p, P(X=0) = 1-p$\n",
    "3. **Mean**: $E(X)=0\\cdot P(X=0) + 1 \\cdot P(X = 1) = p$;\n",
    "4. **Variance**: $\\DeclareMathOperator*{\\Var}{Var} \\Var(X) = (0-p)^2\\cdot P(X=0) + (1-p)^2 \\cdot P(X = 1) = p(1-p$)\n",
    "\n",
    "And the number of event $\\{X = 1\\}$ (the \"success\" trial) is to be counted, during $n$ trials.\n",
    "\n",
    "### Binomial Random Variable\n",
    "The random variable $X$ that **COUNTS** how many defectives out of the $n$ items is called the BINOMIAL $r.v.$ with parameters $n$ and $p$, $X\\sim Binomial(n,p)$.\n",
    "1. **State Space**: $\\{0,1,2,\\dots,n\\}$\n",
    "2. **Distribution func**: $P(X = x) = \\displaystyle \\frac{n!} {x!(n-x)!} p^x (1-p)^{n-x}$\n",
    "3. **Mean**: $\\sum\\limits_{x = 0}^{n} xP(X = x) = \\sum\\limits_{X = 0}^{n} \\displaystyle \\frac{n\\cdot (n-1)!} {(x-1)!(n-x)!} p\\cdot p^{x-1} (1-p)^{n-x} = np$\n",
    "4. **Variance**: $\\sum\\limits_{x = 0}^{n} x^2P(X = x) = np(1-p)$\n",
    "\n",
    "***\n",
    "**Sampling Distribution of a Count**: Choose an SRS of size $n$ from a population with proportion $p$ of successes. When the population is **much larger** than the sample, the count $X$ of successes in the sample has approximately the binomial distribution with parameters $n$ and $p$.\n",
    "\n",
    ">**e.g.** 10% of light bulbs are unqualified. Select $10$ from totally $10000$. How many would be unqualified?\n",
    ">\n",
    ">| Actual Probability | Using the binomial distribution |\n",
    ">| :----------------: |----------------------------------------------------------|\n",
    ">| $$P(X=0) =10!\\times \\frac{9990} {10000} \\times \\frac{9989} {9999} \\times \\cdots \\times \\frac{9980} {9990} = 0.3485$$ | $$P(X=0) = \\binom{10}{0} \\sideset{}{^{0}}{(0.10)} \\sideset{}{^{10}}{(0.90)} = 0.3487$$ |\n",
    "\n",
    "### Proportions\n",
    "The proportion of successes: $\\newcommand{\\ffrac}{\\displaystyle\\frac} \\hat{p} = \\ffrac{X} {n}$\n",
    "1. **Mean**: $p$\n",
    "2. **Variance**: $\\sigma_{\\hat{p}} = \\sqrt{\\ffrac{p(1-p)} {n}}$\n",
    "3. Remember that $\\hat{p}$ is NOT BINOMIAL.\n",
    "\n",
    ">**e.g.** Suppose an issue on $2500$ students and $60\\%$ would agree. What's the probability that sample proportion who agree is at least $58\\%$?\n",
    ">\n",
    ">$\\hat{p} = \\ffrac{X} {2500}$, $X\\sim \\N(2500,0.6)$. Then $P(\\hat{p} \\geq 0.58) = P(X \\geq 2500 \\times 0.58) = P(X \\geq 1450)$. The following work are for JMP\n",
    "\n",
    "***\n",
    "And when $n$ gets larger, through their figures we can find that the distribution of $X$ is approximately *Normal*\n",
    "with **mean** and **standard deviation** $\\mu_X = np$ and $\\sigma_X = \\sqrt{np(1-p)}$ respectively. And the distribution of $\\hat{p}$ is also approximately *Normal* with **mean** and **standard deviation** $\\mu_{\\hat{p}} = p$ and $\\sigma_{\\hat{p}} = \\sqrt{\\ffrac{p(1-p)} {n}}$ respectively. As a rule of thumb, we will use the **Normal approximation** when n is large, to be specific: $np \\geq 10$ and $n(1 – p) \\geq 10$.\n",
    "\n",
    "## Summary\n",
    "For binomial distribution, when $np \\geq 10$ and $n(1 – p) \\geq 10$, large enough, the count $X \\sim \\N \\left(np, \\sqrt{np(1-p)}\\right)$\n",
    "\n",
    "Ane the porpotion $\\hat{p} \\sim \\N \\left( p, \\sqrt{\\ffrac{p(1-p)} {n}} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Inference\n",
    "## Estimating with Confidence\n",
    "### Statistical Estimation\n",
    "Collect data from sample, get statistics, then make an inference about the parameter of the population.\n",
    "\n",
    "**Setting in advance**: Simple Conditions for Inference About a Mean\n",
    "1. We have an SRS from the population of interest. There is no nonresponse or other practical difficulty.\n",
    "2. The variable we measure has an exactly Normal distribution $\\N(\\mu,\\sigma)$ in the population.\n",
    "3. We *don’t know* the population mean $\\mu$, but we *do know* the population standard deviation $\\sigma$.\n",
    "\n",
    "And since we don't know $\\mu$, we can only construct an interval which possibly contains the unknown $\\mu$.\n",
    " \n",
    "First thing is **Confidence level**: $C = 1 - \\alpha$. The probability of that containing happens required. It's a decimal between $0$ and $1$. We can also say it is the overall capture rate of real parameter $\\mu$ of all times of sampling.\n",
    "\n",
    "Then is the **Critical Value**: $z^*$, which satisfies $\\N(z*,0,1) - \\N(-z*,0,1) = C$ (can be found on table). \n",
    "\n",
    "With that we can have **Margin of Error**: $m = \\sigma_{\\bar{X}} \\cdot z^* = z^* \\ffrac{\\sigma} {\\sqrt{n}}$, here the $\\sigma_{\\bar{X}}$ is calculated from the parameter, not statistics, and $n$ is the number of the sample.\n",
    "\n",
    "And finally the **confidence interval**: $\\bar{x} \\pm m$, where $\\bar{x}$ is calculated from the dataset.\n",
    "***\n",
    "Logic behind\n",
    "1. Following the z-table we can know that with probability $C$ sample mean $\\bar{x}$ will be lied in a interval of Two Margin of Error long, with its center the real mean $\\mu$: $\\bar{X} \\sim \\N(\\mu, \\sigma)$\n",
    "2. To say that $\\bar{x}$ lies within a magin of error long away from the parameter $\\mu$ is EQUIVALENT to say that the parameter $\\mu$ lies with those of some $\\bar{x}$\n",
    "3. So among all times of sampling, about probability $C$ will produce the interval that contains parameter $\\mu$\n",
    "***\n",
    "Their relation:\n",
    "\n",
    "Lower $C$, lower $z^*$, lower $m$; lower $\\sigma$, lower $m$; higher $n$, lower $m$.\n",
    "\n",
    "And since $n$ is the easiest to control, we can use our desired $m$ to derive a estimated $n$, then round up to an integer.\n",
    "\n",
    "The conclusion after all of this can be made looks like this: I am $C$ confident that the population mean falls between $\\bar{x} - m$ and $\\bar{x} + m$.\n",
    "\n",
    "### About this method\n",
    "1. Only applied to this distribution\n",
    "2. Data are collected using SRS\n",
    "3. Badly produced data ruins everything\n",
    "4. The confident interval is not resistant to outliers\n",
    "5. $n$ can't be too small\n",
    "6. $\\sigma$ or the population, required\n",
    "7. $m$ covers only random sampling error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests of Significance (Hypothesis Testing)\n",
    "**Tests of Significance**: Comparing obervation with a claim (hypothesis) on certain parameters whose truth is to be questioned. And the result is expressed in terms of probability, called the **p-value**.\n",
    "\n",
    "The original claim is call the **null hypothesis**, $H_0$; and what we are going to prove is the **alternative hypothesis**, which is *two-sided* if it states that the parameter is different from the null value, and *one-sided* if it states that the parameter is bigger or smaller than the null value.\n",
    "\n",
    "***\n",
    "**Test Statistic**: based on a statistic that estimate the parameter in debate. *When $H_0$ is true, the estimate should be near the parameter value.*\n",
    "\n",
    "When normally distributed, the test statistic can be \n",
    "\n",
    "$$z = \\frac{\\text{estimate  -  hypothesized value}} {\\text{standard deviation of the estimate}}$$\n",
    "\n",
    "**p-value**: assuming $H_0$ is true, the probability of the statistic would take the value as extreme or more extreme than the actual one by observation.\n",
    "\n",
    "Then, is the **significant level**: $\\alpha$, a given fixed value.\n",
    "1. *p-value* less than $\\alpha$ → reject $H_0$ → conclude $H_a$ (then we call this result is statistically significant at level $\\alpha$)\n",
    "2. *p-value* greater than or equal to $\\alpha$ → can't reject $H_0$ → can't conclude $H_a$\n",
    "3. for smaller $\\alpha$, it means that we insist on stronger evidence against $H_0$\n",
    "\n",
    ">**e.g.**\n",
    ">\n",
    ">A score. Given normal distribution with unknown $\\mu$, and $\\sigma = 60$. $H_0: \\mu = 0$, $H_a: \\mu \\neq 0$; $\\alpha = 0.05$; Obeservation from $18$ respondents with sample mean $17$.\n",
    ">\n",
    ">First we can derive that $\\sigma_{\\bar{X}} = \\sigma \\, /\\sqrt{n} = 14.1421$, theorically.\n",
    ">Then assuming $H_0$ to be true, calculate the test statistic and p-value:\n",
    ">\n",
    ">$$z = \\frac{\\bar{x} - \\mu_0} {\\sigma \\, / \\sqrt{n}} = 1.2$$\n",
    ">\n",
    ">and for this two-sided alternative hypothesis\n",
    ">\n",
    ">$$\\text{p-value} = P(Z > z \\text{ OR } Z < z) = 2P(Z > 1.2) = 0.2302 > 0.05$$\n",
    ">\n",
    ">Conclusion: Can't reject $H_0$. Such high p-value makes no evidence to support $H_a$.\n",
    "\n",
    "Common steps for this method:\n",
    "1. State the null hypothesis $H_0$ and alternative one $H_a$. Remember, the test is designed to assess the strength of the evidence against $H_0$, and only when it's strong enough can we conclude that $H_0$ is rejected and accept $H_a$\n",
    "2. Calculate the value of *test statistic*, which normally measures how far the data are from $H_0$\n",
    "3. Assuming that $H_0$ is true, find *p-value* for the observed data. This is a probability that the test statistic will weigh against $H_0$ at least as strongly as it does for these observation\n",
    "4. Decide the significance level $\\alpha$, how much evidence against $H_0$ you regard as decisive. blah blah\n",
    "\n",
    "### Connection between the Confident Interval and Hypothesis Test\n",
    ">Following the earlier example\n",
    ">\n",
    ">as $\\alpha = 0.05$, since it's two-sided, then $C = 1-\\alpha = 0.95$, which means the *critical value* $z^*$ is $1.96$, so that the confident interval is $17 \\pm 1.96 \\cdot 14.14 = [-10.7,+34.7]$, which contains the hypothetic value $0$. You can't reject that!\n",
    ">\n",
    ">Or first construct a standard confident interval: $0 \\pm z^* = [-1.96,1.96]$. Then from the given sample mean $\\bar{x} = 17$, we find the corresponding $z=1.2$, which is contained in the standard confident interval. You can't reject that!\n",
    "\n",
    "### $z$ test for a population mean\n",
    "So assume the normal distribution, unknown $\\mu$ and known $\\sigma$. $H_0:\\mu = \\mu_0$. We can calculate the **one-sample $z$ statistic**\n",
    "\n",
    "$$z = \\frac{\\bar{x} - \\mu_0} {\\sigma \\, / \\sqrt{n}}$$\n",
    "\n",
    "Then for each alternative hypothesis, we calculate the *p-value* following the table below.\n",
    "\n",
    "$$\\begin{array}{cc}\n",
    "\\hline\n",
    "H_a & \\text{p-value} \\\\ \\hline\n",
    "\\mu > \\mu_0 & P(Z \\geq z) \\\\\n",
    "\\mu < \\mu_0 & P(Z \\leq z) \\\\\n",
    "\\mu \\neq \\mu_0 & 2\\cdot P(Z \\geq \\left|z\\right|) \\\\ \\hline\n",
    "\\end{array}$$\n",
    "\n",
    ">**comprehensive example**\n",
    ">\n",
    "> A total of $n = 324$ athelets participated. Among the $n = 201$ woman, their average caloric intake is $2403.7$ while the recommand is $2811.5$. Is there evidence that female athletes are deficient in caloric intake?\n",
    ">\n",
    ">$H_0: \\mu = 2811.5$, versus $H_a : \\mu < 2811.5$\n",
    ">\n",
    ">Now given the standard deviation of $880$ from a carry out test. Now we have a $\\sigma_{\\bar{X}} = \\ffrac{\\sigma} {\\sqrt{n}} = \\ffrac{880} {\\sqrt{201}} = 62.0704$. And the test statistic $z = \\ffrac{\\bar{x} - \\mu_0} {\\sigma_{\\bar{X}}} = \\ffrac{2403.7 - 2811.5} {62.0704} = -6.57$. So that the *p-value* is $P(Z < -6.57) \\approx 0$\n",
    ">\n",
    ">So small, then reject $H_0$. And conclude that: there is \"strong evidence\" of below recommended caloric consumption among female athletes.\n",
    ">\n",
    ">Another conclusion: $\\bar{x} = 2403.7$ obtained from sample is ***statistical significantly smaller*** than $\\mu = \\mu_0 = 2811.5$.\n",
    "\n",
    "### Type I and Type II ERROR\n",
    "**Tyle I error**: reject $H_0$ when $H_0$ is true.\n",
    "\n",
    "**Tyle II error**: fail to reject $H_0$ when $H_0$ is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use and Abuse of Tests\n",
    "### When choosing the significant level $\\alpha$\n",
    "1. Is the result serious when errors occur?\n",
    "    1. Type II: Conclude that global warming is real, but actually not\n",
    "    2. Type I: An innocent person was convicted a crime\n",
    "2. Is there a preliminary study? If so you may require a larger $\\alpha$\n",
    "### About the test result\n",
    "1. Statistical significance only says whether the effect observed is likely to be due to chance alone because of random sampling.\n",
    "2. Statistical significance may not be practically important. It warns you the effect but not the magnitude. But still it may be meaningful.\n",
    "3. For too large sample size, significance can be reached even for the tiniest effect.\n",
    "4. Don't use data that suggest hypothesis before sampling.\n",
    "5. Exploratory data analysis is not always bad. And if you find something interest, change to another data set and repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for Distributions\n",
    "## Inference for the Mean of a Population ($\\text{t-Test}$)\n",
    "Draw an SRS of size $n$ from a large population that has a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$. The **one-sample $\\mathrm{t}$ statistic** has the t distribution with degrees of freedom $df = n – 1$.\n",
    "\n",
    "$$t = \\frac{\\bar{x} - \\mu} {s_{\\bar{x}}} \\sim t_{n-1}$$\n",
    "\n",
    "where $s_{\\bar{x}} = \\ffrac{s} {\\sqrt{n}}$, called the **standard error**, and $s$ is the sample standard deviation, and this variable $t$ has the $\\mathrm{t}$ distribution with degrees of freedom $df = n – 1$.\n",
    "\n",
    "$\\odot$And when the degree of freedom increase, the plot get closer to the standard normal curve.$\\Join$\n",
    "***\n",
    "How to use the table?\n",
    "\n",
    "Given sample size $n$, we can calculate the degree of freedom $n-1$, and using the upper-tail probability to find the corresponding probability $\\alpha$ or $\\alpha/2$, with these two new figures we can find the critical value $t$.\n",
    "\n",
    "And then use the $t$ we can find the Confident interval\n",
    "\n",
    "$$\\bar{x} \\pm t \\times \\frac{s} {\\sqrt{n}}$$\n",
    "\n",
    "where $m = t \\times \\frac{s} {\\sqrt{n}}$ is the **margin of error**.\n",
    "***\n",
    "Test of Hypothesis\n",
    "\n",
    "$$\\begin{array}{cc}\n",
    "\\hline\n",
    "H_a & \\text{p-value} \\\\ \\hline\n",
    "\\mu > \\mu_0 & P(T \\geq t) \\\\\n",
    "\\mu < \\mu_0 & P(T \\leq t) \\\\\n",
    "\\mu \\neq \\mu_0 & 2\\cdot P(T \\geq \\left|t\\right|) \\\\ \\hline\n",
    "\\end{array}$$\n",
    "\n",
    ">**e.g.** given $\\alpha = 0.05$, $n=8$, $\\bar{x} = 7.06$, $s = 3.56$; $H_0: \\mu = 5.4, H_{a}: \\mu \\neq 5.4$\n",
    "\n",
    ">First we calculate the Standard Error $\\ffrac{s} {\\sqrt{n}} = \\ffrac{3.56} {\\sqrt{8}} = 1.26$. So that the $\\text{t}$ statistics is\n",
    "\n",
    ">$$t = \\frac{\\bar{x} - \\mu_0} {s_{\\bar{x}}} = 1.40$$\n",
    "\n",
    ">Then look up the table for line of $df=7$ and we can find that\n",
    "\n",
    ">$$\\begin{array}{c:cccc}\n",
    "df & .15 & .10 & .05 & .025 \\\\\n",
    "7 & 1.119 & 1.415 & 1.895 & 2.365\n",
    "\\end{array}$$\n",
    "\n",
    ">So when $T \\geq 1.40$ we might say that the upper-tail probability is approximately $0.11$, somewhere from $0.15$ to $0.10$.\n",
    "\n",
    ">Since is a two-tail test, so that we have the $p\\text{-value} = 2 \\times 0.11 = 0.22 > 0.05$. Can't reject the null hypothesis at $0.05$ level. There is NO SIGNIFICANT DIFFERENCE ( $\\alpha= 5\\%$) BETWEEN ....\n",
    "\n",
    "$\\dagger$\n",
    "- Actually only when the population is normally distributed can we get a $t$ distributed sample, but when the sample size get larger, in practise, that will be OK.\n",
    "- So if the sample size is less than about $15$, use this procedure only if the data are close to normal.\n",
    "- Also, in same condition, CI from $t$ procedure is wider than $z$ procedure and that's the price of not knowing the population standard deviation and with so few samples.\n",
    "- Often a \"significant result\" for a two-sided test can be used to justify a one-sided test for another sample from the same population. Remember: p-value for one-sided test is half of the p-value for 2-sided (tailed) test.\n",
    "- Sometimes, the hypothesis affect the conclusion. So always always use a two-sided test.\n",
    "***\n",
    "\n",
    "Matched Pairs $\\text{t}$ Test Procedures\n",
    "\n",
    "To compare the responses to the two treatments in a matched-pairs design, find the difference between the responses within each pair. Then apply the one-sample t procedures to the differences:\n",
    "\n",
    "We first make two observation on same individual, or one observation on each of two similar individuals, result in **paired data**. If the conditions for inference are met, we can use one-sample $t$ procedures to perform inference about the mean difference $\\mu_d$.\n",
    "\n",
    ">**e.g.** Matched Pairs t Test\n",
    ">\n",
    ">$H_0:\\mu=\\mu_0 = 0$,$H_a = \\mu \\neq 0$. Then from sample:\n",
    "1. Degree of freedom: $df = n-1=14$\n",
    "2. Mean of the sample: $\\bar{x} = 2.433$\n",
    "3. Standard Deviation of the sample: $s= 1.460$\n",
    "4. Standard Error (sample): $SE_{\\bar{x}} = \\ffrac{s} {\\sqrt{n}} = 0.377$\n",
    "5. $t$ statistic: $t = \\ffrac{\\bar{x} - \\mu_0} {SE_{\\bar{x}}} = 6.45$\n",
    ">\n",
    ">Then use the data above to find the p-value in the table, remenber its two-sided hypothesis:\n",
    ">\n",
    ">$p\\text{-value} = 2 \\times \\Pr(T \\geq t) \\approx 0.0002 < \\alpha$. Reject Null Hypothesis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Chapter 6 & 7\n",
    "Lab 6 7 8 9 10\n",
    "### Chapter 5\n",
    "Population and sample, and what's the random variable.\n",
    "\n",
    "Bernoulli, counting\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "229px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
