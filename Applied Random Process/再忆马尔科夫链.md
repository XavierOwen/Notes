# Markov Chain, again

Xavier at 181022

感觉马尔科夫链学的并不好呢

这里想用一个生活化的方式重新学习一遍，便于记忆

内容基于：

- Introduction to Probability Models 10th by Ross
- 高武军老师所授《应用随机过程》的课堂笔记

大致是第四章，第六章的内容



## Markov Chain

### Intro

这里先考虑的是离散时间马尔科夫链。

先有*随机变量*，假定就是一天中的睡觉时间吧（并不想起床），记作$X_i$，并且假定只取整数值，即从$0$到$24$。如此一天一天的睡睡睡睡睡睡。。。我们就有了一个集合$\left\{X_n, n=0,1,2,\dots\right\}$，此为*随机过程*。第$0$天即是游戏开始的时间。

接下来，我们定义一个这样的概率
$$
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\using}[1]{\stackrel{\mathrm{#1}}{=}}
\newcommand{\ffrac}{\displaystyle \frac}
\newcommand{\space}{\text{ }}
\newcommand{\bspace}{\;\;\;\;}
\newcommand{\QQQ}{\boxed{?\:}}
\newcommand{\void}{\left.\right.}
\newcommand{\CB}[1]{\left\{ #1 \right\}}
\newcommand{\SB}[1]{\left[ #1 \right]}
\newcommand{\P}[1]{\left( #1 \right)}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\Tran}[1]{{#1}^{\mathrm{T}}}
\newcommand{\d}[1]{\displaystyle{#1}}
\newcommand{\EE}[2][\,\!]{\mathbb{E}_{#1}\left[#2\right]}
\newcommand{\Var}[2][\,\!]{\mathrm{Var}_{#1}\left[#2\right]}
\newcommand{\Cov}[2][\,\!]{\mathrm{Cov}_{#1}\left(#2\right)}
\newcommand{\Corr}[2][\,\!]{\mathrm{Corr}_{#1}\left(#2\right)}
\newcommand{\I}[1]{\mathrm{I}\left( #1 \right)}
\newcommand{\N}[1]{\mathrm{N} \left( #1 \right)}
\newcommand{\ow}{\text{otherwise}}
P\left\{X_{n+1} = j \mid X_n = i, X_{n-1} = i_{n-1},\dots, X_0 = i_0\right\} = P_{ij}
$$

- for all $n$：无论是一年中的哪一天，这个都成立
- for all $i_0,i_1,\dots,i_{n-1},i,j$：无论前$n$天睡眠状况如何



这个随机过程成为马氏链需要下式成立。
$$
\boxed{P\CB{X_{n+1} = j\mid X_n =i,X_{n-1} = i_{n-1},\cdots, X_0 = i_0} = P\CB{X_{n+1}= j \mid X_n = i} = P_{ij}}
$$

- *马氏性*：直观看，即：今天第$n​$天，我今天睡了2个小时，明天睡12个小时的概率，即$P_{2,12}​$，与昨天、前天、大前天，乃至于直到游戏开始的那天都无关，只与今天有关



注意这本教材默认了时齐性：$P\left\{X_{n+1}=j\mid X_n = i\right\} = P\left\{X_1 = j \mid X_0 = i\right\}$。

> 假定今天是第$0$天，我睡了6个小时，那么明天我睡7个小时的概率就是$P\left\{X_1 = 7 \mid X_0 = 6\right\}$
>
> 那么无论将来的哪一天，比方说第$n$天，我若也是睡了6个小时，接下来的一天就是第$n+1$天，我睡7个小时的概率是$P\left\{X_{n+1} = 7 \mid X_n = 6\right\}$
>
> 这两个概率相同



如此我们关注下*一步转移概率矩阵*。
$$
\sum_{j=0}^{24} P_{ij} = 1, i = 0,1,2,\dots,24\\
\mathbf{P} = \begin{Vmatrix}
P_{00} & P_{01} & P_{02} & \cdots & P_{0,24}\\
P_{10} & P_{11} & P_{12} & \cdots & P_{1,24} \\
\vdots & \vdots & \vdots & \\
P_{i0} & P_{i1} & P_{i2} & \cdots & P_{i,24} \\
\vdots & \vdots & \vdots & \\
P_{24,0} & P_{24,1} & P_{24,2} & \cdots & P_{24,24} 
\end{Vmatrix}
$$
$P_{00}$相当于今天一整天都没睡的情况下，明天还打算一整天不睡的概率；$P_{24,24}$就相当于今天睡了一整天的情况下，明天还打算睡一整天的概率。



> 这里插入两个重要模型
>
> - 随机游动：$P_{i,i+1} = p = 1 - P_{i,i-1}$，$i = 0,\pm 1, \pm 2, \dots$，$0 < p < 1$
> - 赌博模型：$P_{i,i+1} = p = 1 - P_{i,i-1},i = 1,2,\dots,N-1$，$P_{00} = P_{NN} = 1$



### 切普曼－柯尔莫哥洛夫方程

定义$n$步转移概率，即考虑$n$天之后我的睡眠长度。
$$
P_{ij}^{\:\!n} = P\CB{X_{n+k} = j \mid X_{k} = i}, n\geq 0, 24\geq i,j \geq0
$$
如此就有
$$
\begin{align}
P_{ij}^{\:\!n+m} &= P\CB{X_{n+m} = j \mid X_0 = i}\\
&=\sum_{k=0}^{\infty} P\CB{X_{n+m} = j, X_n = k \mid X_0 = i} \\
&= \sum_{k=0}^{\infty} P\CB{X_{n+m} = j \mid X_n = k , X_0 = i} P\CB{X_n = k \mid X_0 = i} \\
&= \sum_{k=0}^{\infty} P_{ik}^{\:\!n}P_{kj}^{\:\!m}\end{align}
$$
$n$步转移矩阵记为$\mathbf{P}^{\P{n}}$，$n$步从时常$i$转移到时长$j$的概率记为$P_{ij}^n$ 。那么该方程即是
$$
\mathbf{P}^{\P{n+m}} = \mathbf{P}^{\P{n}} \cdot \mathbf{P}^{\P{m}}
$$
于是归纳可得：$\mathbf{P}^{\P{n}} = \mathbf{P}^n$。



*击中时*，举个栗子。假设现在受到睡神的祝福，我的可能睡眠时长集合有变化了，多了三种可能：黄金分割常数$\phi$，阿基米德常数$\pi$，和自然常数$e$。一旦我在某天睡眠时长的取值为上述三者，就只能在这三者之间打转了（联系将来吸收态的定义再来理解也可）。若记$\mathscr A=\left\{\phi,\pi,e\right\}$为一个新的睡眠时长状态，$A\in\mathscr A$，定义
$$
W_n = \begin{cases}
X_n, &\text{if }n < N \\
A,   &\text{if }n \leq N
\end{cases}
$$
$N$即是击中时。

则有
$$
\begin{cases}
Q_{i,j} = P_{i,j}, &\text{if } i \notin \mathscr{A}, j \notin \mathscr{A} \\[0.7em]
Q_{i,A} = \d{\sum_{j \in \mathscr{A}} P_{i,j}}, &\text{if } i \notin \mathscr{A} \\
Q_{A,A} = 1
\end{cases}
$$
还有针对状态的击中时：$\tau_j = \inf\CB{n\geq 0:X_n=j}$以及$\tau^+=\inf\CB{n>0:X_n=j}$。



### 状态的分类

- 可达（鸭？）accessible：存在某非负$n$，使得$P_{ij}^{n}>0$﻿。即给定我今天睡了$i$小时，那么从今往后，包括今天的某天睡了$j$小时的概率为正，那么就说可从状态$i$到达状态$j$
- 连接communicate：两个状态，$i$和$j$互相可达，连接的连个状态归为一类。
- 若整个马氏链只有一个类，成为不可约马氏链
- 复发态，暂住态：首先定义$f_{ij} = P\CB{\text{ever return }j \mid X_0 = i}$，那么就有$f_{ii} = P\CB{\text{ever return }i \mid X_0 = i}$，且
  - 状态$i$为复发态：$f_{ii}=1$
  - 状态$i$为暂住态：$f_{ii}<1$
  - 怎么理解呢？这儿可以说是一个涉及到睡神的概念了。考虑我今天睡了5小时，将来还有没有几率能再睡5小时，复发态意味着一定可以，可以说是睡神的祝福；暂住态意味着不一定，即，我有可能再也不能有这样长度的睡眠时长，可以说是。。。睡神的诅咒了。

对于暂住态$i$，有个小结论：显然停留总次数是个几何分布，胜利概率$p=1-f_{ii}$，即，永不再停留。这个分布的均值是$\dfrac{1}{1-f_{ii}}$。



通过考虑示性函数
$$
I_n = \begin{cases}
1, & \text{if }X_n = i\\
0, & \text{if }X_n \neq i
\end{cases}
$$
我们可以计算*期望停留次数*：$\EE{\d{\sum_{n=0}^{N}I_n} \mid X_0 = i}=\d{\sum_{n=0}^{\infty} P_{ii}^{n}}$，并得出结论，

- 状态$i$为复发态：$\d{\sum_{n=1}^{\infty}}P_{ii}^{n} = \infty$
- 状态$i$为暂住态：$\d{\sum_{n=1}^{\infty}}P_{ii}^{n} < \infty$



我们还可以证明复发和暂住都可以拓展定义在一个状态类上。如此又有一个小结论：既然*有限状态马氏链*不能每个状态都是暂住的，那么对于*有限状态**不可约**马氏链*，一定每个状态都是复发的。



### 长远时间比例（平稳概率）与极限概率

首先定义*期望击中时*：$m_{ij} = \EE{\tau_j^+ \mid X_0 = i} = \sum\limits_{n=1}^{\infty} n\cdot P\CB{\tau_j^+ = n\mid X_0 = i} \equiv \sum\limits_{n=1}^{\infty} n\cdot f^{\P{n}}_{ij}$，即是从状态$i$出发，之后第一次出现状态$j$所耗的平均时长。这里
$$
f^{\P{n}}_{ij} =P\CB{\tau_j^+ = n\mid X_0 = i}\equiv P_i\CB{ \tau_j^+ = n } = P\CB{X_n = j,X_m\neq j,1\leq m < n}
$$
还可以看出和之前的联系：$f_{ij} = P\CB{\text{ever return }j \mid X_0 = i} = \sum\limits_{n=1}^{\infty} f_{ij}^{\P{n}} = P\CB{\exists\, n>0, \space s.t.\space X_n=j\mid X_0=i}$

再定义正复发和空复发。

- $m_{ii} = \infty$：空复发，需要无限的时间，我才可以再撞到一次同样的睡眠时长，来自睡神的虚假的祝福。
- $m_{ii} <\infty$：正复发，嗯，只要有限的时间，我就可以再撞到一次同样的睡眠时长。

可以证明空复发与正复发都是可以拓展定义到类的层面的。如此也有一个小结论：对于*有限状态**不可约**马氏链*，则该马氏链一定是正复发的，不能是空复发的。

于是对于*不可约，复发马氏链*，定义长远时间比例，或者平稳概率：$\pi_j = \dfrac{1}{m_{jj}}​$，即是：长期来看，我睡眠时长为$i​$的概率。

$Theorem$
$$
\begin{cases}
\pi_j = \d{\sum_i \pi_i \cdot P_{i,j}},\bspace j \geq 1\\
\d{\sum_j \pi_j = 1}
\end{cases}
$$
