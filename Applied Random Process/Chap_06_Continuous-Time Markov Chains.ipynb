{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous-Time Markov Chains\n",
    "## Introduction\n",
    "***Pure birth process*** and ***birth and death model***.\n",
    "## Continuous-Time Markov Chains\n",
    "\n",
    "$\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\DeclareMathOperator*{\\argmax}{argmax}\n",
    "\\DeclareMathOperator*{\\plim}{plim}\n",
    "\\newcommand{\\ffrac}{\\displaystyle \\frac}\n",
    "\\newcommand{\\d}[1]{\\displaystyle{#1}}\n",
    "\\newcommand{\\space}{\\text{ }}\n",
    "\\newcommand{\\bspace}{\\;\\;\\;\\;}\n",
    "\\newcommand{\\bbspace}{\\;\\;\\;\\;\\;\\;\\;\\;}\n",
    "\\newcommand{\\QQQ}{\\boxed{?\\:}}\n",
    "\\newcommand{\\void}{\\left.\\right.}\n",
    "\\newcommand{\\Tran}[1]{{#1}^{\\mathrm{T}}}\n",
    "\\newcommand{\\CB}[1]{\\left\\{ #1 \\right\\}}\n",
    "\\newcommand{\\SB}[1]{\\left[ #1 \\right]}\n",
    "\\newcommand{\\P}[1]{\\left( #1 \\right)}\n",
    "\\newcommand{\\abs}[1]{\\left| #1 \\right|}\n",
    "\\newcommand{\\norm}[1]{\\left\\| #1 \\right\\|}\n",
    "\\newcommand{\\given}[1]{\\left. #1 \\right|}\n",
    "\\newcommand{\\using}[1]{\\stackrel{\\mathrm{#1}}{=}}\n",
    "\\newcommand{\\asim}{\\overset{\\text{a}}{\\sim}}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\EE}{\\mathbb{E}}\n",
    "\\newcommand{\\II}{\\mathbb{I}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\ZZ}{\\mathbb{Z}}\n",
    "\\newcommand{\\QQ}{\\mathbb{Q}}\n",
    "\\newcommand{\\PP}{\\mathbb{P}}\n",
    "\\newcommand{\\AcA}{\\mathcal{A}}\n",
    "\\newcommand{\\FcF}{\\mathcal{F}}\n",
    "\\newcommand{\\AsA}{\\mathscr{A}}\n",
    "\\newcommand{\\FsF}{\\mathscr{F}}\n",
    "\\newcommand{\\dd}{\\mathrm{d}}\n",
    "\\newcommand{\\I}[1]{\\mathrm{I}\\left( #1 \\right)}\n",
    "\\newcommand{\\N}[1]{\\mathcal{N}\\left( #1 \\right)}\n",
    "\\newcommand{\\Exp}[1]{\\mathrm{E}\\left[ #1 \\right]}\n",
    "\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n",
    "\\newcommand{\\Avar}[1]{\\mathrm{Avar}\\left[ #1 \\right]}\n",
    "\\newcommand{\\Cov}[1]{\\mathrm{Cov}\\left( #1 \\right)}\n",
    "\\newcommand{\\Corr}[1]{\\mathrm{Corr}\\left( #1 \\right)}\n",
    "\\newcommand{\\ExpH}{\\mathrm{E}}\n",
    "\\newcommand{\\VarH}{\\mathrm{Var}}\n",
    "\\newcommand{\\AVarH}{\\mathrm{Avar}}\n",
    "\\newcommand{\\CovH}{\\mathrm{Cov}}\n",
    "\\newcommand{\\CorrH}{\\mathrm{Corr}}\n",
    "\\newcommand{\\ow}{\\text{otherwise}}\n",
    "\\newcommand{\\FSD}{\\text{FSD}}\n",
    "\\newcommand{\\SSD}{\\text{SSD}}\\CB{X\\P t,t\\geq 0}$ is a ***continuous-time Markov chain*** if $\\forall\\; s,t \\geq 0$ and *nonnegative* integers $i,j,x\\P u$, $0\\leqq u < s$, we have\n",
    "\n",
    "$\\bspace P\\CB{X\\P{t+s} = j \\mid X\\P s = i,X\\P u = x\\P u,0\\leq u<s} = P\\CB{X\\P{t+s} = j\\mid X\\P s = i}$\n",
    "\n",
    "meaning that the conditional distribution of the future $X\\P{t+s}$ given the present $X\\P s$ and the past $X\\P u$ for $0\\leq u < s$, depends *only on the present* and is *independent of the past*. If $P\\CB{X\\P{t+s} = j\\mid X\\P s = i}$ is independent of $s$, the we say this **continuous-time Markov chain** have ***stationary*** or ***homogeneous transition probabilities***.\n",
    "\n",
    "***\n",
    "\n",
    "Another way to define this. Consider this as a stochastic process having the properties that each time it enters state $i$\n",
    "\n",
    "1. the amount of time it spends in that state before making a transition into a different state is **exponentially distributed** with mean, say $1/v_i$\n",
    "2. and when the process leaves state $i$, it next enters state $j$ with some probability, say, $P_{ij}$. Of course, the $P_{ij}$ must satisfy, $\\forall\\; i$\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P_{ii} = 0&\\\\\n",
    "\\sum_j P_{ij} = 1&\n",
    "\\end{align}$\n",
    "\n",
    "In addition, the amount of time the process spends in state $i$, $T_i$, should be independent of the time the next state visited. With this we have $P\\CB{T_i > s+t\\mid T_i > s} = P\\CB{T_i > t}$, $\\forall\\; s,t\\geq 0$. Hence, the random variable $T_i$ is memoryless and must thus be **exponenetially distributed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birth and Death Processes\n",
    "A system, with states are represented by the number of people in the system at that time. Suppose that whenever there're $n$ people in the system,\n",
    "\n",
    "1. new arrivals enter the system at an exponential rate $\\lambda_n$\n",
    "2. people leave the system at an exponential rate $\\mu_n$\n",
    "\n",
    "then we have the state transition rates and probabilities\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "v_0 &= \\lambda_0,\\\\\n",
    "v_i &= \\lambda_i + \\mu_i,\\bspace i>0 \\\\\n",
    "P_{01} &= 1,\\\\\n",
    "P_{i,i+1} &= \\ffrac{\\lambda_i}{\\lambda_i + \\mu_i},\\bspace i>0\\\\\n",
    "P_{i,i-1} &= \\ffrac{\\mu_i}{\\lambda_i + \\mu_i},\\bspace i>0\n",
    "\\end{align}$\n",
    "\n",
    "Note that $v_i$ represents the rate of time that either a birth or a death occurs, which is exponentially distributed with rate $\\lambda_i + \\mu_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.2** Poisson Process\n",
    "\n",
    "A birth and death process for which $\\forall\\; n \\geq 0$, we have\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "\\mu_n &= 0\\\\\n",
    "\\lambda_n &= \\lambda\n",
    "\\end{align}\\newcommand{\\wp}{\\text{with probability }}$\n",
    "\n",
    "**e.g.3** Yule process\n",
    "\n",
    "Consider a population whose members can only give birth to new members but cannot die, with each member acting independently and the time for each member giving birth exponentially distributed with rate $\\lambda$. Let $X\\P t$ be the population size at time $t$, then $\\CB{X\\P t,t\\geq0}$ is a pure birth process with $\\lambda_n = n\\lambda$, $n\\geq 0$.\n",
    "\n",
    "**e.g.4** A Linear Growth Model with Immigration\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "\\mu_n &= n\\mu, &n\\geq 1\\\\\n",
    "\\lambda_n &= n\\lambda + \\theta,& n\\geq 0\n",
    "\\end{align}$\n",
    "\n",
    "This is the ***linear growth process with immigration***. Suppose that $X\\P 0 = i$ and let $M\\P t = \\Exp{X\\P t}$. Now solve $M\\P t$.\n",
    "\n",
    ">$M\\P{t+h} = \\Exp{X\\P{t+h}} = \\Exp{\\Exp{X\\P{t+h}\\mid X\\P t}}$\n",
    ">\n",
    ">So given the population at time $t$, the population at time $t+h$ could be the following with certain probabilities.\n",
    ">\n",
    ">$\\bspace X\\P{t+h} = \\begin{cases}\n",
    "X\\P t + 1,&\\wp \\P{\\theta + X\\P t \\lambda}\\cdot h + o\\P h\\\\\n",
    "X\\P t - 1,&\\wp \\P{X\\P t \\mu} \\cdot h + o\\P h\\\\\n",
    "X\\P t,& \\wp 1 - \\P{\\theta + X\\P t \\lambda + X\\P t +\\mu}\\cdot h + o\\P h\n",
    "\\end{cases}$\n",
    ">\n",
    ">Therefore, $\\Exp{X\\P{t+h}\\mid X\\P t} = X\\P t + \\P{\\theta + X\\P t \\lambda - X\\P t \\mu}\\cdot h + o\\P h$ and taking the expectation yields $M\\P{t+h} = M\\P t + \\P{\\lambda - \\mu}M\\P t \\cdot h + \\theta \\cdot h + o\\P h$\n",
    ">\n",
    ">Letting $h\\to0$ we have $M'\\P t = \\P{\\lambda - \\mu}M\\P t + \\theta$. Solve the equation, we have\n",
    ">\n",
    ">$\\bspace M\\P t = \\ffrac{\\theta}{\\lambda - \\mu} \\P{e^{\\P{\\lambda - \\mu}t} - 1} +ie^{\\P{\\lambda - \\mu}t}$\n",
    ">\n",
    ">Finally by the fact that $M\\P 0 = i$ we reach the final solution that \n",
    ">\n",
    ">$\\bspace M\\P t = \\theta t + i$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.5** The Queueing System, $M/M/1$\n",
    "\n",
    "Consider a single-server station. Customers arrives in accordance with a Poisson process having rate $\\lambda$. Upon arrival, each customer goes directly into service if the server is free; if not, then the customer joins the queue. The successive service times are assumed to be independent exponential random variables having mean $1/\\mu$ (or rate $\\mu$).\n",
    "\n",
    "The preceding is known as the $M/M/1$ queueing system. The first $M$ refers to the fact that the interarrival process is ***Markovian***, since it's a Poisson process and the second to the fact that the service distribution is **exponential**, hence, **Markovian**. The $1$ refers to the fact that there's only one server.\n",
    "\n",
    "And we can write this system as a birth and death process with\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "\\mu_n &= \\mu,&n\\geq 1\\\\\n",
    "\\lambda_n &= \\lambda,& n\\geq 0\n",
    "\\end{align}$\n",
    "***\n",
    "\n",
    "**e.g.6** A Multiserver Exponential Queueing System\n",
    "\n",
    "Now there're $s$ servers and thus the birth and death process is with parameters\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "\\mu_n &= \\begin{cases}\n",
    "n\\mu,& 1\\leq n \\leq s\\\\\n",
    "s\\mu,& n > s\\\\\n",
    "\\end{cases}\\\\\n",
    "\\lambda_n &= \\lambda, \\bbspace n\\geq 0\n",
    "\\end{align}$\n",
    "\n",
    "And this is known as $M/M/s$ queueing model.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement a deeper discussion on the mean and variance of the process. Consider a general birth and death process with birth rates $\\CB{\\lambda_n}$ and death rates $\\CB{\\mu_n}$ where $\\mu_0 = 0$. And let $T_i$ denote the time, starting from state $i$, it takes for the process to enter state $i+1$, $i\\geq0$. Recursively, we can compute $\\Exp{T_i}$, $i\\geq 0$. Firstly\n",
    "\n",
    "$\\bspace \\Exp{T_0 } = \\ffrac{1}{\\lambda_0}$\n",
    "\n",
    "Then for $i>0$, we condition whether the first transition takes the process into state $i-1$ or $i+1$. Here's the indicator variable and the corresponding conditional expectation\n",
    "\n",
    "$\\bspace I_i = \\begin{cases}\n",
    "1,&\\text{from state } i \\text{ to state } i+1\\\\ \n",
    "0,&\\text{from state } i \\text{ to state } i-1\\\\ \n",
    "\\end{cases} \\bspace\\Longrightarrow\\bspace \\left\\{\\begin{align}\n",
    "\\Exp{T_i \\mid I_i = 1} &= \\ffrac{1}{\\lambda_i + \\mu_i}\\\\\n",
    "\\Exp{T_i \\mid I_i = 0} &= \\ffrac{1}{\\lambda_i + \\mu_i} + \\Exp{T_{i-1}} + \\Exp{T_i}\\\\\n",
    "\\end{align}\\right.\\bspace\\Longrightarrow$\n",
    "\n",
    "$\\bspace\\begin{align}\\Exp{T_i} &= \\ffrac{1}{\\lambda_i + \\mu_i} \\cdot \\ffrac{\\lambda_i}{\\lambda_i + \\mu_i} + \\P{\\ffrac{1}{\\lambda_i + \\mu_i} + \\Exp{T_{i-1}} + \\Exp{T_i}} \\cdot \\ffrac{\\mu_i}{\\lambda_i + \\mu_i} \\\\\n",
    "&= \\ffrac{1}{\\lambda_i + \\mu_i} + \\ffrac{\\mu_i}{\\lambda_i + \\mu_i} \\cdot\\P{\\Exp{T_{i-1}} + \\Exp{T_i}}\\\\\n",
    "&= \\ffrac{1}{\\lambda_i} + \\ffrac{\\mu_i}{\\lambda_i}\\cdot\\Exp{T_{i-1}},\\bspace i\\geq 1\n",
    "\\end{align}$\n",
    "\n",
    "Suppose now that we wanted to determine the expected time to go from state $i$ to state $j$ where $i<j$. Using the preceding, this quantity will equal to $\\Exp{T_i} + \\cdots + \\Exp{T_{j-1}}$\n",
    "\n",
    "**e.g.7**\n",
    "\n",
    "Now the birth and death process with $\\lambda_i \\equiv \\lambda$ and $\\mu_i \\equiv \\mu$, we have\n",
    "\n",
    "$\\bspace\\Exp{T_i} = \\ffrac{1}{\\lambda} + \\ffrac{\\mu}{\\lambda} \\Exp{T_{i-1}}\\Rightarrow \\Exp{T_i} = \\ffrac{1}{\\lambda} \\P{1+\\ffrac{\\mu}{\\lambda} + \\P{\\ffrac{\\mu}{\\lambda}}^2 + \\cdots + \\P{\\ffrac{\\mu}{\\lambda}}^i} = \\ffrac{ 1- \\P{\\mu/\\lambda}^{i+1}}{\\lambda - \\mu},\\bspace i\\geq 0$\n",
    "\n",
    "and the expected time to reach state $j$ from state $k$, for $k<j$, is\n",
    "\n",
    "$\\bspace \\Exp{\\text{time to go from state } i \\text{ to }j} = \\d{\\sum_{i=k}^{j-1} \\Exp{T_{i-1}}} = \\ffrac{j-k}{\\lambda- \\mu}-\\ffrac{\\P{\\mu/\\lambda}^{k+1}}{\\lambda - \\mu} \\ffrac{\\P{1-\\P{\\mu/\\lambda}^{j-k}}}{1-\\mu/\\lambda} $\n",
    "\n",
    "Further if we assume that $\\lambda = \\mu$, $\\Exp{T_i} = \\ffrac{i+1}{\\lambda}$ and the preceding degenerate to\n",
    "\n",
    "$\\bspace \\Exp{\\text{time to go from state } i \\text{ to }j} = \\ffrac{j\\P{j+1} - k\\P{k+1}}{2\\lambda}$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we have the variance of the time to go from state $0$ to $i+1$ using the similar reasoning. We first rewrite the conditional expectation of $T_i$ on $I_i$.\n",
    "\n",
    "$\\bspace \\Exp{T_i \\mid I_i}=\\ffrac{1}{\\lambda_i + \\mu_i} + \\P{1-I_i} \\P{\\Exp{T_{i-1}}+\\Exp{T_i}} \\Longrightarrow$\n",
    "\n",
    "$\\bspace \\Var{\\Exp{T_i \\mid I_i}} = \\P{\\Exp{T_{i-1}}+\\Exp{T_i}}^2 \\cdot\\Var{I_i} = \\P{\\Exp{T_{i-1}}+\\Exp{T_i}}^2\\ffrac{\\mu_i\\lambda_i}{\\P{\\mu_i + \\lambda_i}^2}$\n",
    "\n",
    "And if we let $X_i$ denote the time until the transition from $i$ occurs, then\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "\\Var{T_i\\mid I_i =1}&= \\Var{X_i \\mid I_i = 1} \\\\\n",
    "&= \\Var{X_i}  = \\P{\\ffrac{1}{\\lambda_i + \\mu_i}}^2 \\\\\n",
    "\\Var{T_i\\mid I_i =0}&=  \\Var{X_i + \\text{time to get back to }i + \\text{time to reenter }i+1}\\\\\n",
    "&= \\Var{X_i} + \\Var{T_{i-1}} + \\Var{T_i} \\\\[0.7em]\n",
    "\\Longrightarrow \\Var{T_i\\mid I_i} &= \\Var{X_i} + \\P{1-I_i} \\P{\\Var{T_{i-1}} + \\Var{T_i}}\\\\\n",
    "\\Longrightarrow \\Exp{\\Var{T_i\\mid I_i}} &= \\P{\\ffrac{1}{\\lambda_i + \\mu_i}}^2 + \\ffrac{\\mu_i}{\\lambda_i + \\mu_i} \\P{\\Var{T_{i-1}} + \\Var{T_i}}\\\\\n",
    "\\Longrightarrow \\Var{T_i} &= \\Var{\\Exp{T_i \\mid I_i}} + \\Exp{\\Var{T_i\\mid I_i}}\\\\\n",
    "&= \\P{\\ffrac{1}{\\lambda_i + \\mu_i}}^2 + \\ffrac{\\mu_i}{\\lambda_i + \\mu_i}\\P{\\Var{T_{i-1}} + \\Var{T_i}} + \\ffrac{\\mu_i\\lambda_i}{\\P{\\mu_i + \\lambda_i}^2}\\P{\\Exp{T_{i-1}}+\\Exp{T_i}}^2\n",
    "\\end{align}$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$\\bspace \\Var{T_i} = \\ffrac{1}{\\lambda_i\\P{\\lambda_i + \\mu_i}}+ \\ffrac{\\mu_i}{\\lambda_i} \\Var{T_{i-1}} + \\ffrac{\\mu_i}{\\lambda_i +\\mu_i} \\P{\\Exp{T_{i-1}} + \\Exp{T_i}}^2$\n",
    "\n",
    "Additionally, about the time to go from state $k$ to $j$, we have\n",
    "\n",
    "$\\bspace \\Var{\\text{time to go from $k$ to $j$}} = \\d{\\sum_{i=k}^{j-1} \\Var{T_i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transition Probability Function $P_{ij}\\P t$\n",
    "\n",
    "First let $P_{ij}\\P t = P\\CB{X\\P{t+s} = j \\mid X\\P s = i}$. Note that in this very expression, æ—¶é½æ€§ä¸Žé©¬æ°æ€§ both are contained. We can have a first glance on pure birth process. Let $X_k$ denote the time the process spends in state $k$ before making a transition into state $k+1$, $k\\geq 1$. Then $\\sum_{k=1}^{j-1} X_k$ is the time it takes until the process enters state $j$ given it currently in state $i$. And we have two equivalent events\n",
    "\n",
    "$\\bspace X\\P t < j \\iff X_i + X_{i+1} + \\cdots + X_{j-1} > t$\n",
    "\n",
    "Therefore, for $i<j$, if $\\forall i \\neq j, \\lambda_i \\neq \\lambda_j $\n",
    "\n",
    "$\\bspace \\begin{align}\n",
    "P\\CB{X\\P t < j \\mid X\\P 0 = i} &= P\\CB{\\sum_{k=i}^{j-1} X_k > t}\\\\\n",
    "&= \\sum_{k=i}^{j-1}\\P{ e^{-\\lambda_k \\cdot t} \\prod_{r\\neq k,r=i}^{j-1} \\ffrac{\\lambda_r}{\\lambda_r - \\lambda_k}}\\\\\n",
    "P\\CB{X\\P t = j \\mid X\\P 0 = i} &= P\\CB{X\\P t < j+1 \\mid X\\P 0 = i} - P\\CB{X\\P t < j \\mid X\\P 0 = i} \\\\\n",
    "&= \\sum_{k=i}^{j}\\P{ e^{-\\lambda_k \\cdot t} \\prod_{r\\neq k,r=i}^{j} \\ffrac{\\lambda_r}{\\lambda_r - \\lambda_k}} - \\sum_{k=i}^{j-1} \\P{e^{-\\lambda_k \\cdot t} \\prod_{r\\neq k,r=i}^{j-1} \\ffrac{\\lambda_r}{\\lambda_r - \\lambda_k}}\\\\ \n",
    "&= P_{ij}\\P t \\\\\n",
    "P_{ii}\\P t &= P\\CB{X_i > t} = e^{-\\lambda_i \\cdot t}\n",
    "\\end{align}$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the general cases, considering the corresponding ***Chapmanâ€“Kolmogorov equations*** we have\n",
    "\n",
    "$Lemma.3$\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P_{ij}\\P{t+s} &= P\\CB{X\\P{t+s} = j \\mid X\\P0 = i}\\\\\n",
    "&= \\sum_{k=0}^\\infty P\\CB{X\\P{t+s} = j,X\\P t = k \\mid X\\P0 = i}\\\\\n",
    "&= \\sum_{k=0}^\\infty P\\CB{X\\P{t+s} = j \\mid X\\P0 = i,X\\P t = k}\\cdot P\\CB{X\\P t = k \\mid X\\P0 = i}\\\\\n",
    "&= \\sum_{k=0}^\\infty P\\CB{X\\P{t+s} = j \\mid X\\P t = k}\\cdot P\\CB{X\\P t = k \\mid X\\P0 = i}\\\\\n",
    "&= \\sum_{k=0}^\\infty P_{kj}\\P s \\cdot P_{ik}\\P t = \\sum_{k=0}^\\infty P_{ik}\\P t P_{kj}\\P s\n",
    "\\end{align}$\n",
    "\n",
    "We then derive \n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P_{ij}'\\P t &= \\lim_{h \\to 0} \\ffrac{P_{ij}\\P{t+h} - P_{ij}\\P t}{h}= \\lim_{h \\to 0} \\ffrac{ \\P{\\sum\\limits_{k\\neq i} P_{ik}\\P h \\cdot P_{kj} \\P t} - \\P{1-P_{ii}\\P h} P_{ij}\\P t}{h} \\\\\n",
    "&= \\lim_{h \\to 0}\\P{ \\sum_{k\\neq i} \\ffrac{P_{ik}\\P h}{h}P_{kj} \\P t - \\P{\\ffrac{1-P_{ii}\\P h}{h}}P_{ij}\\P t }\n",
    "\\end{align}$\n",
    "\n",
    "To find the limit, we assume that we can interchange the limit and the summation in the preceding, and obtain\n",
    "\n",
    "$\\bspace \\d{P_{ij}'\\P t = \\sum_{k\\neq i}\\P{ \\lim_{h \\to 0} \\ffrac{P_{ik}\\P h}{h}}P_{kj} \\P t - \\lim_{h \\to 0}\\P{\\ffrac{1-P_{ii}\\P h}{h}}P_{ij}\\P t}$\n",
    "\n",
    "Now to find $\\lim_{h \\to 0} \\ffrac{P_{ik}\\P h}{h}$ and $\\lim_{h \\to 0}\\ffrac{1-P_{ii}\\P h}{h}$, we need to introduce $q_{ij}$, which is defined as (***different from the textbook!!! Frecking!!!***)\n",
    "\n",
    "$\\bspace q_{ij} = \\begin{cases}\n",
    "v_i P_{ij}, & j\\neq i\\\\\n",
    "-\\sum\\limits_{i\\neq j} q_{ij} = -v_i,& j = i\n",
    "\\end{cases}, \\bspace \\d{\\forall \\: i, \\sum_{j}q_{ij} = 0}$\n",
    "\n",
    "Since $v_i$ is the rate at which the process makes a transition when in state $i$ and $P_{ij}$ (from $\\mathbf P$) is the probability that this transition is into state $j$, it follows that $q_{ij}$ is the rate, when in state $i$, at which the process makes a transition into state $j$, called the ***instantaneous transition rates***.\n",
    "\n",
    "After this we have\n",
    "\n",
    "$Lemma.2$\n",
    "\n",
    ">$\\bspace\\d{\\lim_{h \\to 0}}\\ffrac{1-P_{ii}\\P h}{h} = v_i,\\bspace \\d{\\lim_{h \\to 0}} \\ffrac{P_{ij}\\P h}{h} = q_{ij}, i\\neq j$\n",
    "\n",
    "$Proof$\n",
    "\n",
    ">Skipped...\n",
    "\n",
    "Then after so many efforts, we finally make it to\n",
    "\n",
    "$Theorem.1$ Kolmogorovâ€™s Backward Equations\n",
    "\n",
    ">For all states $i$, $j$, and times $t\\geq 0$,\n",
    ">\n",
    ">$\\bspace \\d{P_{ij}'\\P t = \\sum_{k\\neq i} q_{ik}P_{kj}\\P t - v_i P_{ij}\\P t}$\n",
    "\n",
    "$Remark$\n",
    "\n",
    ">We also write $q_{ii} = -v_i = -q_i$ where $q_i = \\abs{q_{ii}}>0$, thus, $P_{ii} = 0$ and $P_{ij} = \\ffrac{q_{ij}}{q_{i}} = \\ffrac{q_{ij}}{\\sum_{j\\neq i} q_{ij}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.9** Pure Birth Process\n",
    "\n",
    "The backward equations for the pure birth process\n",
    "\n",
    ">$\\bspace\\begin{align}\n",
    "P_{ij}'\\P{t} &= \\sum_{k\\neq i,i+1} 0\\cdot P_{kj}\\P t + q_{i,i+1} P_{i+1,j} \\P t - v_i P_{ij}\\P t\\\\\n",
    "&= v_i \\cdot P_{i,i+1}P_{i+1,j}\\P t - \\P{\\lambda_i + 0} P_{ij}\\P t\\\\\n",
    "&= \\lambda_i \\ffrac{\\lambda_i}{\\lambda_i + 0}P_{i+1,j}\\P t - \\lambda_i P_{ij}\\P t\\\\\n",
    "&= \\lambda_i P_{i+1,j}\\P t - \\lambda_i P_{ij}\\P t\n",
    "\\end{align}$\n",
    "***\n",
    "\n",
    "**e.g.10** Birth and Death Process\n",
    "\n",
    "The backward equations for the birth and death process\n",
    "\n",
    ">$\\bspace\\begin{align}\n",
    "P_{0j}'\\P{t} &= v_0 P_{01}P_{1j}\\P t - v_0 P_{0j}\\P t = \\lambda_0 P_{1j}\\P t - \\lambda_0 P_{0j} \\P t = \\lambda_0\\P{P_{1j}\\P t - P_{0j}\\P t}\\\\\n",
    "P_{1j}'\\P t &= v_i\\P{P_{i,i+1}P_{i+1,j}\\P t + P_{i,i-1}P_{i-1,j}\\P t} - v_i P_{ij}\\P t\\\\\n",
    "&= \\P{\\lambda_i + \\mu_i}\\P{\\ffrac{\\lambda_i}{\\lambda_i + \\mu_i} P_{i+1,j}\\P t + \\ffrac{\\mu_i}{\\lambda_i + \\mu_i} P_{i-1,j}\\P t} - \\P{\\lambda_i + \\mu_i}P_{ij}\\P t\\\\\n",
    "&= \\lambda_i P_{i+1,j}\\P t + \\mu_i P_{i-1,j}\\P t - \\P{\\lambda_i + \\mu_i}P_{ij}\\P t,\\bspace i > 0\n",
    "\\end{align}$\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another set of equations, similarly, are \n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P_{ij}'\\P t &= \\lim_{h \\to 0} \\ffrac{P_{ij}\\P{t+h} - P_{ij}\\P t}{h}= \\lim_{h \\to 0} \\ffrac{ \\P{\\sum\\limits_{k\\neq j} P_{ik}\\P t \\cdot P_{kj} \\P h} - \\P{1-P_{jj}\\P h} P_{ij}\\P t}{h} \\\\\n",
    "&= \\lim_{h \\to 0}\\P{ \\sum_{k\\neq j} P_{ik} \\P t \\ffrac{P_{kj}\\P h}{h} - \\P{\\ffrac{1-P_{jj}\\P h}{h}}P_{ij}\\P t }\\\\\n",
    "\\end{align}$\n",
    "\n",
    "Still we assume that we can interchange limit with summation, we obtain, from $Lemma.2$\n",
    "\n",
    "$Theorem.2$ Kolmogorovâ€™s Forward Equations\n",
    "\n",
    ">Under suitable regularity conditions, say, models with finite states, or all birth and death processes,\n",
    ">\n",
    ">$\\bspace \\d{P_{ij}'\\P t = \\sum_{k\\neq j} P_{ik}\\P t q_{kj}- v_j P_{ij}\\P t}$\n",
    "\n",
    "For the pure birth process, the forward equation is written as  \n",
    "\n",
    "$\\bspace \\begin{align}\n",
    "P_{ij}'\\P t &= \\sum_{k\\neq j,j-1} P_{ik}\\P t q_{kj} + P_{i,j-1}\\P t q_{j-1,j} - v_j P_{ij}\\P t\\\\\n",
    "&= 0 + P_{i,j-1}\\P t \\cdot \\lambda_{j-1} \\ffrac{\\lambda_{j-1}}{\\lambda_{j-1} + 0} - \\lambda_j P_{ij}\\P t \\\\\n",
    "&= \\lambda_{j-1} P_{i,j-1}\\P t - \\lambda_j P_{ij}\\P t\\\\\n",
    "&=\\begin{cases}\n",
    "-\\lambda_i P_{ii}\\P t,& j=i\\\\\n",
    "\\lambda_{j-1} P_{i,j-1}\\P t - \\lambda_j P_{ij}\\P t, & j\\geq i+1\n",
    "\\end{cases}\n",
    "\\end{align}$\n",
    "\n",
    "Then we solve the ODE and obtain\n",
    "\n",
    "$Proposition.4$ Pure Birth Process\n",
    "\n",
    ">$\\bspace \\begin{align}\n",
    "P_{ii}\\P t &= e^{-\\lambda_i t}, && i \\geq 0\\\\\n",
    "P_{ij}\\P t &= \\lambda_{j-1} e^{-\\lambda_j t}\\int_0^t e^{-\\lambda_j s}P_{i,j-1} \\P s \\;\\dd s, && j \\geq i+1\n",
    "\\end{align}$\n",
    "\n",
    "$Proof$\n",
    "\n",
    ">Just keep in mind that $P_{ii}\\P 0 = 1$ and $P_{ij}\\P 0 = 0$ and it can't be more obvious\n",
    "\n",
    "**e.g.12** Birth and Death Process\n",
    "\n",
    "The forward equation now is\n",
    "\n",
    ">$\\bspace\\begin{align}\n",
    "P_{0j}'\\P{t} &= \\sum_{k\\neq 0} P_{ik}\\P t q_{k0} - v_0 P_{i0}\\P t\\\\\n",
    "&= \\sum_{k\\neq 0,1} P_{ik}\\P t q_{k0} + P_{i1}\\P t q_{10} - \\lambda_0 P_{i0}\\P t\\\\\n",
    "&= 0 + P_{i1}\\P t v_1 P_{10} - \\lambda_0 P_{i0}\\P t\\\\\n",
    "&= P_{i1}\\P t \\P{\\lambda_1 + \\mu_1}\\ffrac{\\mu_1}{\\lambda_1 + \\mu_1}- \\lambda_0 P_{i0}\\P t\\\\\n",
    "&= \\mu_1 P_{i1}\\P t- \\lambda_0 P_{i0}\\P t\\\\\n",
    "P_{1j}'\\P t &= P_{i,j-1}\\P t q_{j-1,j} + P_{i,j+1}\\P t q_{j+1,j} - v_j P_{ij}\\P t\\\\\n",
    "&= P_{i,j-1}\\P t \\P{\\lambda_{j-1} + \\mu_{j-1}}\\ffrac{\\lambda_{j-1}}{\\lambda_{j-1} + \\mu_{j-1}} + P_{i,j+1}\\P t \\P{\\lambda_{j+1} + \\mu_{j+1}} \\ffrac{\\mu_{j+1}}{\\lambda_{j+1} + \\mu_{j+1}} - \\P{\\lambda_j + \\mu_j}P_{ij}\\P t\\\\\n",
    "&= \\lambda_{j-1}P_{i,j-1}\\P t + \\mu_{j+1}P_{i,j+1}\\P t  \\P{\\lambda_j + \\mu_j}P_{ij}\\P t\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting Probabilities\n",
    "In analogy with discrete-time Markov chains, the probability that a continuous-time Markov chain will be in state $j$ at time $t$ often converges to a limiting value that is independent of the initial state.\n",
    "\n",
    "$\\bspace P_j \\equiv \\d{\\lim_{t\\to\\infty} P_{ij}\\P t}$\n",
    "\n",
    "where we are assuming that the limit *exists* and is *independent of the initial state* $i$.\n",
    "\n",
    "To find $P_{j}$, consider the **forward equations**.\n",
    "\n",
    "$\\bspace P_{ij}'\\P t = \\d{\\sum_{k \\neq j} P_{ik}\\P t q_{kj} - v_j P_{ij}\\P t \\Longrightarrow \\lim_{t\\to\\infty} P_{ij}'\\P t = \\sum_{k \\neq j} P_k \\cdot q_{kj} - v_j \\cdot P_j}$\n",
    "\n",
    "for all states $i$ and $\\sum_j P_j = 1$ will do the problem. One last thing is to note that $\\d{\\lim_{t\\to\\infty} P_{ij}'\\P t = 0}$, since if not, then with $t\\to \\infty$, $P_{ij}\\P t$ will move to either $+\\infty$ or $-\\infty$. So in short, we have\n",
    "\n",
    "$\\bspace \\begin{cases}\n",
    "\\sum\\limits_{k \\neq j} P_k \\cdot q_{kj} - v_j \\cdot P_j = 0, & \\forall\\: j\\\\\n",
    "\\sum\\limits_j P_j = 1\n",
    "\\end{cases}$\n",
    "\n",
    "$Remark$\n",
    "\n",
    ">**backword equations** won't do, since\n",
    ">\n",
    ">$\\bspace P_{ij}'\\P t = \\d{\\sum_{k \\neq i} q_{ik} P_{kj}\\P t - v_i P_{ij}\\P t \\Longrightarrow \\lim_{t\\to\\infty} P_{ij}'\\P t = \\sum_{k \\neq i} q_{ik} P_j - v_i \\cdot P_j =P_j\\sum_k q_{ik} = P_j \\cdot 0= 0}$\n",
    ">\n",
    ">And the two sufficient conditions for the existence $P_j$ are\n",
    ">\n",
    ">- ***irreducible***: all states of the Markov chain ***communicate***, meaning that there's positive probability of starting in state $i$ and ever being in state $j$, for all $i$, $j$. Or in mathematical form: *Let $S$ be the state space*. $\\forall \\: i,j\\in S$, $\\exists\\: t > 0$, $s.t.$ $P_{ij}\\P t > 0$. And if not, the two states are in different classes.\n",
    ">- ***positive recurrrent***: *starting in any state, the mean time to return to that state is finite*\n",
    ">\n",
    ">Unfortunately to decide whether a continuous-time Markov chain is **positive recurrent** is not a easy job. Write $\\mathbf Q = \\P{q_{ij}}$ and still we have $-q_{ii} = v_i = q_i$. If $\\sup q_i < \\infty$ and $\\inf q_i > 0$, whether state $i$ is **positive recurrent** can be determined exactly the same way as if we're dealing with a discrete-time Markov Chain. Later we'll show that **time reversible** $\\Rightarrow$ **positive recurrent**: $\\d{\\lim_{t\\to\\infty} P_{ii}\\P t > 0}$\n",
    ">\n",
    ">And more about **recurrent**. In discrete-time Markov Chain, beinig **recurrent** means $f_{ii} = \\sum_{n=1}^\\infty f_{ii}^\\P{n} = 1 \\iff \\sum_{n=1}^\\infty P_{ii}^\\P{n} = \\infty$. Now in continuous-time Markov Chain, we change the summation to integral, $\\d{\\int_{0}^\\infty P_{ii}\\P t\\;\\dd t = \\infty}$.\n",
    ">\n",
    ">**Irreducibility** is an easier job now. First we update some notation. $\\mathbf Q = \\P{q_{ij}}$, $\\mathbf P\\P t = \\P{P_{ij}\\P{t}}$, and the **jump chain** or the **embedded chain** (ref [Time Reversibility](#Time-Reversibility)), $\\mathbf P = \\P{P_{ij}}$.\n",
    ">\n",
    ">And from $\\mathbf Q$ we can easily write $\\mathbf P$ like\n",
    ">\n",
    ">$\\bspace \\mathbf Q = \\begin{pmatrix}\n",
    "-v_1 & q_{12} & q_{13}\\\\ \n",
    "q_{21} & -v_2 & q_{23}\\\\ \n",
    "q_{31} & q_{32} & -v_3\n",
    "\\end{pmatrix} \\iff \\mathbf P = \\begin{Vmatrix}\n",
    "0 & \\ffrac{q_{12}}{v_1} & \\ffrac{q_{13}}{v_1}\\\\ \n",
    "\\ffrac{q_{21}}{v_2} & 0 & \\ffrac{q_{23}}{v_2}\\\\ \n",
    "\\ffrac{q_{31}}{v_3} & \\ffrac{q_{32}}{v_3} & 0\n",
    "\\end{Vmatrix}$\n",
    ">\n",
    ">Since it's too hard to derive $\\mathbf P\\P t = \\P{P_{ij}\\P{t}}$, although you can do so that you can directly see whether such $t$ exists so that $P_{ij}\\P t > 0$, we suggest handling $\\mathbf P$ as if it were a transition probabilities matrix from a discrete-time Markov Chain.\n",
    ">\n",
    ">And since through working on $\\mathbf P$ we can decide whether the Markov Chain is **irreducible**, and $\\mathbf P$ is equivalent to $\\mathbf Q$, could we obtain the conclusion by only working on $\\mathbf Q$. **YES YOU CAN!**\n",
    ">\n",
    ">*Our object is to find whether there's an $n$ such that $q_{ij}^\\P{n} > 0$, where $q_{ij}^\\P{n}$ have the similar definitions like $\\d{P_{ij}^{n} = \\sum_{k=0}^\\infty P_{ik}^{m} P_{kj}^{n-m}}$*.\n",
    "\n",
    "$Remark$ \n",
    "\n",
    ">Up to this point, back to solving the equation to obtain the **limiting probabilities**, remember we **CANNOT** first obtain $\\mathbf P$ and solve $\\begin{cases}\n",
    "\\pi = \\pi \\mathbf P\\\\\n",
    "\\pi \\cdot \\mathbf 1 = 1\n",
    "\\end{cases}$, whose solution is the **limiting distribution** of the **jump chain**...\n",
    ">\n",
    ">So, anyway, if we also define $\\pi_i = \\d{\\lim_{t \\to \\infty} P_{ii}\\P t}$, the equation could be simplied as\n",
    "\n",
    ">$\\bspace\\begin{cases}\n",
    "\\sum\\limits_{k \\neq j} P_k \\cdot q_{kj} - v_j \\cdot P_j = \\pi \\mathbf Q = 0, & \\forall\\: j\\\\\n",
    "\\sum\\limits_j \\pi_j =\\pi\\cdot \\mathbf 1 =  1\n",
    "\\end{cases}$\n",
    ">\n",
    ">And more **importantly**, **this equation set has a solution** $\\iff$ **the limiting probabilities or the stationary probabilities exist**.\n",
    ">\n",
    ">And if it exists, we call this Markov Chain ***ergodic***.\n",
    ">\n",
    ">And we do this because it's hard to find the limiting probabilities in **Continuous Markov Chain** while at that time, **limiting probabilities** $\\Leftrightarrow$ **stationary probabilities**. Thus we let the **stationary probabilities** be a row vector $\\pi$ with $\\pi = \\pi P\\P{t}$.\n",
    ">\n",
    ">And this requires that $\\d{\\lim_{t\\to 0} \\dfrac{P\\P t - I}{t} = P'\\P 0 \\equiv Q}$ or, $\\d{\\lim_{t\\to 0} \\dfrac{P_{ij}\\P t - \\delta_{ij}}{t} = q_{ij}}$.\n",
    ">\n",
    ">Here $Q$, is a matrix with zero row sum, negative diagram entries and all other positive probabilities. Also we see that $P\\P 0 = I$, $i.e.$, $P_{ij}\\P0 = \\delta_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Remark$\n",
    "\n",
    ">$\\sum\\limits_{k \\neq j} P_k \\cdot q_{kj} - v_j \\cdot P_j =0$, this equation (also known as the ***balance equations***) has one more intepretation:\n",
    ">\n",
    ">- $v_j \\cdot P_j$ is the *rate at which the process **leaves** state $j$*: When the process is in state $j$, it leaves at rate $v_j$; and $P_j$ is the *proportion of time it is in state $j$*\n",
    ">- $\\sum\\limits_{k \\neq j} P_k \\cdot q_{kj}$ is the *rate at which the process **enters** state $j$*: for all states named $k$ other than $j$, the *process enters $j$ at a rate $q_{kj}$*; and $P_k$ is the *proportion of time it is in state $k$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now determine the limiting probabilities for a birth and death process. For each state, from $0$ to $n\\geq1$, we have a table\n",
    "\n",
    "$$\\begin{array}{cc}\\hline\n",
    "\\text{State} & \\text{Rate at which leave} = \\text{rate at which enter}\\\\ \\hline\n",
    "0 & \\lambda_0 P_0 = \\mu_1 P_1 \\\\\n",
    "1 & \\P{\\lambda_1+\\mu_1}P_1 = \\mu_2P_2 + \\lambda_0 P_0 \\\\\n",
    "2 & \\P{\\lambda_2+\\mu_2}P_2 = \\mu_3P_3 + \\lambda_1 P_1 \\\\\n",
    "n,n\\geq 1 & \\P{\\lambda_n+\\mu_n}P_n = \\mu_{n-1}P_{n-1} + \\lambda_{n+1} P_{n+1}\\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Adding these equations together, we have $\\forall\\: n\\geq 0$, $\\lambda_n P_n = \\mu_{n+1}P_{n+1}$. Solving these inductively, we have, in terms of $P_0$\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P_1 &= \\ffrac{\\lambda_0}{\\mu_1}P_0 \\\\\n",
    "P_2 &= \\ffrac{\\lambda_1}{\\mu_2}P_1 = \\ffrac{\\lambda_1\\lambda_0}{\\mu_2\\mu_1}P_0 \\\\\n",
    "P_3 &= \\ffrac{\\lambda_2}{\\mu_3}P_2 = \\ffrac{\\lambda_2\\lambda_1\\lambda_0}{\\mu_3\\mu_2\\mu_1}P_0 \\\\\n",
    "&\\vdots\\\\\n",
    "P_n &= \\ffrac{\\lambda_{n-1}}{\\mu_n}P_{n-1} = \\ffrac{\\lambda_{n-1}\\lambda_{n-2}\\cdots\\lambda_2\\lambda_1\\lambda_0}{\\mu_n\\mu_{n-1}\\cdots\\mu_2\\mu_1}P_0\n",
    "\\end{align}$\n",
    "\n",
    "And by using the fact that $\\sum_{n=0}^\\infty P_n = 1 $, we can solve for $P_0$ that\n",
    "\n",
    "$\\bspace P_0 = \\ffrac{1}{1 + \\sum\\limits_{n=1}^{\\infty}\\ffrac{\\lambda_{n-1}\\lambda_{n-2}\\cdots\\lambda_2\\lambda_1\\lambda_0}{\\mu_n\\mu_{n-1}\\cdots\\mu_2\\mu_1}} \\Rightarrow P_n = \\ffrac{\\lambda_0 \\lambda_1 \\cdots \\lambda_{n-1}}{\\mu_1 \\mu_2\\cdots \\mu_n\\P{1 + \\sum\\limits_{n=1}^{\\infty}\\ffrac{\\lambda_{n-1}\\lambda_{n-2}\\cdots\\lambda_2\\lambda_1\\lambda_0}{\\mu_n\\mu_{n-1}\\cdots\\mu_2\\mu_1}}},\\bspace n\\geq1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foregoing equations also show us to the *necessary* condition that the limiting probabilities exist:\n",
    "\n",
    "$\\bspace \\d{\\sum\\limits_{n=1}^{\\infty}\\ffrac{\\lambda_{n-1}\\lambda_{n-2}\\cdots\\lambda_2\\lambda_1\\lambda_0}{\\mu_n\\mu_{n-1}\\cdots\\mu_2\\mu_1} < \\infty}$\n",
    "\n",
    "(and this condition is also *sufficient*.)\n",
    "\n",
    "And in **e.g.6**, the multiserver exponential queueing system, we have the condition reduced to\n",
    "\n",
    "$\\bspace \\d{\\sum_{n=s+1}^\\infty \\ffrac{\\lambda^n}{\\P{s\\mu}^n}<\\infty \\iff \\ffrac{\\lambda}{s\\mu}<1}$\n",
    "\n",
    "In **e.g.4**, the linear growth model with immigration, the condition is reduced to\n",
    "\n",
    "$\\bspace \\d{\\sum_{n=1}^\\infty \\ffrac{\\theta\\P{\\theta+\\lambda}\\cdots\\P{\\theta+\\P{n-1}\\lambda}}{n!\\mu^n}<\\infty \\iff \\lim_{n\\to\\infty} \\ffrac{\\ffrac{\\theta\\P{\\theta+\\lambda}\\cdots\\P{\\theta+n\\lambda}}{\\P{n+1}!\\mu^{n+1}}}{\\ffrac{\\theta\\P{\\theta+\\lambda}\\cdots\\P{\\theta+\\P{n-1}\\lambda}}{n!\\mu^n}} = \\lim_{n\\to\\infty}\\ffrac{\\theta+n\\lambda}{\\P{n+1}\\mu} = \\ffrac{\\lambda}{\\mu}<1}$\n",
    "\n",
    "$Remark$\n",
    "\n",
    ">The previous method to find the limit of a summationis called the ***ratio test***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.13** Machine Repair Model\n",
    "\n",
    "There're $M$ machines and $1$ serviceman. Suppose that the amount of time each machine runs(survives) before breaking down is *exponentially distributed with mean* $\\ffrac{1}{\\lambda}$, and suppose that the amount of time that it takes for the serviceman to fix a machine is exponentially distributed with mean $\\ffrac{1}{\\mu}$. Show time!\n",
    "\n",
    ">Usually, we'll focus on those that are **NOT** in use. We say the system is in state $n$ whenever $n$ machines are not in use, then the preceding is a *birth and death process* having parameters\n",
    ">\n",
    ">$\\bspace\\begin{align}\n",
    "\\mu_n &= \\mu,\\bbspace\\bbspace\\:\\!\\; n\\geq 1\\\\\n",
    "\\lambda_n &= \\begin{cases}\n",
    "\\P{M-n}\\lambda, & n\\leq M\\\\\n",
    "0, & n>M\n",
    "\\end{cases}\n",
    "\\end{align}$\n",
    ">\n",
    ">where a *failing* machine is regarded as an *arrival* and a *fixed* machine as a *departure*. With this we have the $P_0$\n",
    ">\n",
    ">$\\bspace\\begin{align}\n",
    "P_0 &= \\ffrac{1}{1+\\sum\\limits_{n=1}^M\\P{M\\lambda \\P{M-1}\\lambda \\cdots \\P{M-n+1}\\lambda \\cdot \\mu^{-n}}} = \\ffrac{1}{1+\\sum\\limits_{n=1}^M \\P{\\ffrac{M!}{\\P{M-n}!}\\P{\\ffrac{\\lambda}{\\mu}}^n}}\\\\\n",
    "P_n &= \\ffrac{\\ffrac{M!}{\\P{M-n}!}\\P{\\ffrac{\\lambda}{\\mu}}^n}{1+\\sum\\limits_{n=1}^M \\P{\\ffrac{M!}{\\P{M-n}!}\\P{\\ffrac{\\lambda}{\\mu}}^n}},\\bspace n=0,1,\\dots,M\n",
    "\\end{align}$\n",
    ">\n",
    ">We then find the average number of machines not in use\n",
    "\n",
    ">$\\bspace \\d{\\sum_{n=0}^MnP_n = \\ffrac{\\sum\\limits_{n=0}^M\\P{n\\cdot\\ffrac{M!}{\\P{M-n}!}\\P{\\ffrac{\\lambda}{\\mu}}^n}}{1+\\sum\\limits_{n=1}^M \\P{\\ffrac{M!}{\\P{M-n}!}\\P{\\ffrac{\\lambda}{\\mu}}^n}}}$\n",
    ">\n",
    ">And the long-run proportion of time that a given machine is working, which is equivalent to the limiting probability of the machine working\n",
    ">\n",
    ">$\\bspace\\begin{align}\n",
    "P\\CB{\\text{machine } i\\text{ is working}} &= \\sum_{n=0}^M P\\CB{\\text{machine } i\\text{ is working} \\mid \\text{state }n}\\cdot P_n\\\\\n",
    "&= \\sum_{n=0}^M P\\CB{\\text{machine } i\\text{ is not one of the }n\\text{ broken machines}}\\cdot P_n\\\\\n",
    "&= \\sum_{n=0}^M \\ffrac{M-n}{M}P_n = 1 - \\sum_{n=0}^M\\ffrac{nP_n}{M}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Reversibility\n",
    "\n",
    "For an **ergodic** **continuous-time** Markov chain, with limiting probablities $P_i$, ignoring the amount of time spent in each state, then this sequence constitutes a **discrete-time** Markov chain with transition probabilities $P_{ij}$, called ***jump chain*** or ***embedded chain***. This is also **ergodic** and we denote its limiting probabilities as $\\pi_i$. That is, $\\pi_i$ is the unique solution of \n",
    "\n",
    "$\\bspace \\left\\{\\begin{align}\n",
    "\\pi_i &= \\sum\\nolimits_j \\pi_j P_{ji}, & \\forall\\: i\\\\\n",
    "\\sum\\nolimits_i \\pi_i &= 1\n",
    "\\end{align}\\right. \\iff  $$\\left\\{\\begin{align}\n",
    "\\pi &= \\pi \\mathbf P\\\\\n",
    "\\pi \\cdot \\mathbf 1 &= 1\n",
    "\\end{align}\\right.$\n",
    "\n",
    "Thus, intuitively, $P_i = \\ffrac{\\pi_i/v_i}{\\sum\\limits_j\\pi_j/v_j}$. Alternatively (or to check the intuition<span style=\"font-size:50px;\">ðŸ˜†</span>), since for the limiting probabilities, the equality $\\forall\\: i$, $v_i P_i = \\sum\\limits_{j\\neq i} P_j \\, q_{ji}$ must hold, or equivalently since $P_{ii} = 0$, $v_i P_i = \\sum\\limits_{j} P_j v_j P_{ji}$, after plug it in,\n",
    "\n",
    "$\\bspace \\pi_i = \\d{\\sum_j \\pi_j P_{ji}},\\bspace \\forall\\: i$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the reversed process. Suppose now that the **continuous-time** Markov chain has been in operation for a long time and we trace the process going back from time $T$. First note that\n",
    "\n",
    "$\\bspace\\begin{align}\n",
    "P&\\CB{\\text{process is in state }i\\text{throughout }\\SB{t-s,t}\\mid X\\P t = i}\\\\\n",
    "&= \\ffrac{\\text{process is in state }i\\text{throughout }\\SB{t-s,t}}{P\\CB{X\\P t = i}}\\\\\n",
    "&= \\ffrac{P\\CB{X\\P{t-s} = i}e^{-v_i\\cdot s}}{P\\CB{X\\P t = i}}\\\\\n",
    "&\\using{\\text{large }t}e^{-v_i\\cdot s}\n",
    "\\end{align}$\n",
    "\n",
    "In other words, *going backward in time, the amount of time the process spends in state $i$ is also exponentially distributed with rate $v_i$*. And our conclusion is that\n",
    "\n",
    "$\\bspace$*The continuous-time Markov chain will be **time reversible**, in the sense that the process reversed in time has the same probabilistic structure as the original process, if the **embedded chain** is **time reversible***. That is:\n",
    "\n",
    "$\\bspace\\forall\\: i,j\\bspace \\pi_i P_{ij} = \\pi_j P_{ji}$\n",
    "\n",
    "And further using the fact that $P_i = \\ffrac{\\pi_i/v_i}{\\sum\\limits_j\\pi_j/v_j}$, the preceding condition is equivalent to\n",
    "\n",
    "$\\bspace\\forall\\: i,j\\bspace P_i \\cdot q_{ij} = P_j \\cdot q_{ji}$\n",
    "\n",
    "which has the interpretation: *the rate at which the process goes directly from state $i$ to state $j$ is equal to the rate at which it goes directly from $j$ to $i$*.\n",
    "\n",
    "$Remark$\n",
    "\n",
    ">**Time reversible** $\\Rightarrow$ **POSITIVE recurrent** (From Instructor GAO Wujun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Proposition.5$\n",
    "\n",
    ">An ergodic birth and death process is time reversible.\n",
    "\n",
    "Recall that a process is time reversible $iff$\n",
    "\n",
    "$\\bspace\\forall\\: i,j\\bspace P_i \\cdot q_{ij} = P_j \\cdot q_{ji}$\n",
    "\n",
    "Thus, if, as lucky as we are, able to find a set of numbers $P_i$ such that the foregoing is satisfied, then the Markov chain is **time reversible** and the $P_i$s are the **long-run probabilities**. That is,\n",
    "\n",
    "$Proposition.7$\n",
    "\n",
    ">If for some set $\\CB{P_i}$, $\\d{\\sum_i P_i = 1}$, $P_i \\geq 0$ and $\\forall\\: i\\neq j$, $P_i \\cdot q_{ij} = P_j \\cdot q_{ji}$, then the continuous-time Markov chain is **time reversible** and $P_i$ represents the **limiting probability** of being in state $i$.\n",
    "\n",
    "$Proof$\n",
    "\n",
    ">For fixed $i$ we obtain upon summing $P_i \\cdot q_{ij} = P_j \\cdot q_{ji}$ over all $j \\neq i$\n",
    ">\n",
    ">$\\bspace \\d{\\sum_{j\\neq i}P_i \\cdot q_{ij} = \\sum_{j\\neq i}P_j \\cdot q_{ji}}$\n",
    ">\n",
    ">since $\\sum_{j\\neq i} q_{ij} = v_i$, the preceding is just equivalent to\n",
    ">\n",
    ">$\\bspace \\d{v_i P_i = \\sum_{j\\neq i}P_j \\cdot q_{ji}}$\n",
    ">\n",
    ">That's just the **balance equations**! Thus, $P_i$s are the **limiting probabilities**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a **continuous-time** Markov chain with state space $S$, the ***truncated*** to the set $A \\subset S$ one is obtained by further define $q_{ij} = 0$, $\\forall\\: i\\in A$, $j\\notin A$. That is:\n",
    "\n",
    "$\\bspace$*Transitions out of the class $A$ are no longer allowed, whereas ones in $A$ continue at the same rates as before*. A useful result is that: *if the chain is **time reversible**, then so is the **truncated** one.\n",
    "\n",
    "$Proposition.8$\n",
    "\n",
    ">A time reversible chain with limiting probabilities $P_j$, $j\\in S$ that is truncated to the set $A\\in S$ and remains *irreducible*, is also time reversible and has limiting probabilities $P_j^A$ given by\n",
    ">\n",
    ">$\\bspace P_j^A = \\ffrac{P_j}{\\sum\\limits_{i\\in A}P_i},\\bspace j\\in A$\n",
    "\n",
    "$Proof$\n",
    "\n",
    ">By $Proposition\\,6.7$, we need to show that, with $P_j^A = \\ffrac{P_j}{\\sum\\limits_{i\\in A}P_i}$,\n",
    ">\n",
    ">$\\bspace P_i^A q_{ij} = P_j^A q_{ji},\\bspace $for $i\\in A$, $j\\in A$\n",
    ">\n",
    ">Or equivalently, $P_i^A q_{ij} = P_j^A q_{ji}$ for $i\\in A$, $j\\in A$. But this follows since the original chain is, by assumption, time reversible.\n",
    "\n",
    "$Proposition.9$\n",
    "\n",
    ">If $\\CB{X_i\\P t, t\\geq 0}$ are, for $i=1,\\dots,n$, *independent* **time reversible** **continuous-time** Markov chains, then the vector process $\\CB{\\P{X_i\\P t,\\dots,X_n\\P t},t\\geq 0}$ is also a **time reversible continuous-time** Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reversed Chain\n",
    "Skipped\n",
    "## Uniformization\n",
    "Skipped\n",
    "## Computing the Transition Probabilities\n",
    "Now the backward equations is rewritten as (here we use a slightly different notation from the textbook...)\n",
    "\n",
    "$\\d{\\bspace P_{ij}'\\P t = \\sum_{k\\neq i}q_{ik}P_{kj}\\P t - v_i P_{ij}\\P t = \\sum_{k} q_{ik}P_{kj}\\P t } \\Rightarrow \\mathbf P'\\P t= \\mathbf Q \\mathbf P\\P t$\n",
    "\n",
    "and similarly the forward ond, $\\mathbf P'\\P t= \\mathbf P\\P t \\mathbf Q$. We then solve the equation and obtain\n",
    "\n",
    "$\\bbspace\\mathbf P\\P t = \\mathbf P\\P 0 \\cdot e^{\\mathbf Q \\cdot t}$\n",
    "\n",
    "Since $\\mathbf P\\P 0 =\\mathbf I$, this yields that $\\mathbf P\\P t = e^{\\mathbf Q \\cdot t} = \\sum\\limits_{n=0}^\\infty \\mathbf Q^n\\ffrac{t^n}{n!}$\n",
    "\n",
    "And that's not for practical uses, so we need to introduce two approximation method:\n",
    "\n",
    "- $\\d{e^{\\mathbf R t} = \\lim_{n\\to\\infty} \\P{\\mathbf I + \\mathbf R\\ffrac{t}{n}}^n }$\n",
    "- for large $n$, $\\d{e^{-\\mathbf R t} = \\lim_{n\\to\\infty} \\P{\\mathbf I - \\mathbf R\\ffrac{t}{n}}^n}\\Rightarrow \\mathbf P\\P t = \\P{\\mathbf I - \\mathbf R\\ffrac{t}{n}}^{-n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "128px",
    "width": "334px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
