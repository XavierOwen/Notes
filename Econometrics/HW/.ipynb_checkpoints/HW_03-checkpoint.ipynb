{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Econometrics HW_01</center>\n",
    "**<center>11510691 程远星$\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\newcommand{\\using}[1]{\\stackrel{\\mathrm{#1}}{=}}\n",
    "\\newcommand{\\ffrac}{\\displaystyle \\frac}\n",
    "\\newcommand{\\space}{\\text{ }}\n",
    "\\newcommand{\\bspace}{\\;\\;\\;\\;}\n",
    "\\newcommand{\\QQQ}{\\boxed{?\\:}}\n",
    "\\newcommand{\\void}{\\left.\\right.}\n",
    "\\newcommand{\\CB}[1]{\\left\\{ #1 \\right\\}}\n",
    "\\newcommand{\\SB}[1]{\\left[ #1 \\right]}\n",
    "\\newcommand{\\P}[1]{\\left( #1 \\right)}\n",
    "\\newcommand{\\dd}{\\mathrm{d}}\n",
    "\\newcommand{\\Tran}[1]{{#1}^{\\mathrm{T}}}\n",
    "\\newcommand{\\d}[1]{\\displaystyle{#1}}\n",
    "\\newcommand{\\EE}[2][\\,\\!]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\Var}[2][\\,\\!]{\\mathrm{Var}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\Cov}[2][\\,\\!]{\\mathrm{Cov}_{#1}\\left(#2\\right)}\n",
    "\\newcommand{\\Corr}[2][\\,\\!]{\\mathrm{Corr}_{#1}\\left(#2\\right)}\n",
    "\\newcommand{\\I}[1]{\\mathrm{I}\\left( #1 \\right)}\n",
    "\\newcommand{\\N}[1]{\\mathrm{N} \\left( #1 \\right)}\n",
    "\\newcommand{\\ow}{\\text{otherwise}}$</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "$\\P{\\text i}$\n",
    "\n",
    "$\\bspace \\EE{\\hat\\theta_1} = \\EE{\\hat\\beta_1 + \\hat\\beta_2} = \\EE{\\hat\\beta_1 } + \\EE{\\hat\\beta_2} = \\beta_1 + \\beta_2 = \\theta_1$\n",
    "\n",
    "$\\P{\\text ii}$\n",
    "\n",
    "$\\bspace \\begin{align}\n",
    "\\Var{\\hat\\theta_1} &= \\Var{\\hat\\beta_1 + \\hat\\beta_2} \\\\\n",
    "&= \\Var{\\hat\\beta_1} + \\Var{\\hat\\beta_2} + 2\\cdot \\Cov{\\hat\\beta_1, \\hat\\beta_2} \\\\\n",
    "&= \\Var{\\hat\\beta_1} + \\Var{\\hat\\beta_2} + 2\\cdot \\text{Corr}\\P{\\hat\\beta_1, \\hat\\beta_2}\\cdot\\sqrt{\\Var{\\hat\\beta_1}}\\cdot\\sqrt{\\Var{\\hat\\beta_2}}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "$\\P{i}$ \n",
    "\n",
    "$\\bspace$Far from same or nearly same! From the formula given in the textbook we can write:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tilde{\\beta}_1 &= \\ffrac{\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}y_i}}{\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}^2}}\\\\\n",
    "&= \\ffrac{\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}\\P{\\hat\\beta_0 + \\hat\\beta_1 x_{i1} + \\hat\\beta_2 x_{i2} + \\hat \\beta_3 x_{i3} + \\hat u_i}}} {\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}^2}} \\\\\n",
    "&= 0 + \\hat\\beta_1 + \\hat\\beta_2 \\cdot \\ffrac{\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}\\P{x_{i2} - \\bar{x}_2}}} {\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}^2}} + \\hat\\beta_3 \\cdot \\ffrac{\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1} \\P{x_{i3} - \\bar{x}_3}}} {\\d{\\sum_{i=1}^{n}\\P{x_{i1}-\\bar{x}_1}^2}} \\\\\n",
    "&= \\hat\\beta_1 + \\hat\\beta_2 \\cdot \\ffrac{\\Cov{x_1,x_2}} {\\Var{x_1}} + \\hat\\beta_3 \\cdot \\ffrac{\\Cov{x_1,x_3}} {\\Var{x_1}}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\bspace$Given the context that $x_{2,3}$ have large partial effects on $y$, $\\hat\\beta_2$ and $\\hat\\beta_3$ can't be small. And since $x_1$ is highly correlated with $x_2$ and $x_3$ in the sample, we can draw the conclusion that $\\left|\\ffrac{\\Cov{x_1,x_2}} {\\Var{x_1}}\\right|$ and $\\left|\\ffrac{\\Cov{x_1,x_3}} {\\Var{x_1}}\\right|$ are close to $1$.\n",
    "\n",
    "$\\bspace$Thus, if they two are of the same sign, $\\hat\\beta_1$ ad $\\tilde\\beta_1$ are very different; while if are of different signs, $\\hat\\beta_1$ ad $\\tilde\\beta_1$ might be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\P{\\text{ii}}$\n",
    "\n",
    "$\\bspace$This time the two might be just similar because $\\left|\\ffrac{\\Cov{x_1,x_2}} {\\Var{x_1}}\\right|$ and $\\left|\\ffrac{\\Cov{x_1,x_3}} {\\Var{x_1}}\\right|$ are close to $0$ now.\n",
    "\n",
    "$\\P{\\text{iii}}$\n",
    "\n",
    "$\\bspace$It's easy to write the formula for $\\text{se}\\P{\\hat\\beta_1}$:\n",
    "\n",
    "$$\\text{se}\\P{\\hat\\beta_1} = \\sqrt{\\widehat{\\Var{\\hat\\beta_1}}} = \\sqrt{\\ffrac{1} {\\text{SST}_1 \\P{1-R_1^2}}}\\hat\\sigma$$\n",
    "\n",
    "$\\bspace$with $\\hat\\sigma^2 = \\ffrac{1} {n-3-1} \\sum \\hat u_i^2$. And analogously, we have\n",
    "\n",
    "$$\\text{se}\\P{\\tilde\\beta_1} = \\sqrt{\\widehat{\\Var{\\tilde\\beta_1}}} = \\ffrac{\\tilde\\sigma} {\\sqrt{\\text{SST}_1 }}$$\n",
    "\n",
    "$\\bspace$with $\\tilde\\sigma^2 = \\ffrac{1} {n-1-1} \\sum \\hat{ \\dot u}_i^2$. $\\hat{ \\dot u}_i$ is the residual from the model: $y = \\dot\\beta_0 + \\dot\\beta_1 x_1 + \\dot u$\n",
    "\n",
    "$\\bspace$So much easier to see now. First thing is that $x_2$ and $x_3$ have small partial effects on $y$ thus $\\hat{\\dot u}$ and $\\hat u$ can be very similar and thus same for $\\hat\\sigma^2$ and $\\tilde\\sigma^2$ when $n$ is large enough.\n",
    "\n",
    "$\\bspace$Since $x_1$ is highly correlated with $x_2$ and $x_3$, $R_1^2$ can be very close to one.\n",
    "\n",
    "$\\bspace$Summary on these two consideration, a conclusion can be drawn that $\\text{se}\\P{\\hat\\beta_1}$ is such a bigger number than $\\text{se}\\P{\\tilde\\beta_1}$.\n",
    "\n",
    "$\\P{\\text{iv}}$\n",
    "\n",
    "$\\bspace$At this time $R_1^2$ is close to $0$ and thus in terms of their denominators, nothing can we say. However since $x_2$ and $x_3$ are having large partial effects on $y$ thus $\\left|\\hat{\\dot u}\\right|$ could be so much greater than just $\\left|\\hat u\\right|$ and thus the same for $\\tilde\\sigma^2$ and $\\hat\\sigma^2$. And finally, we say that $\\text{se}\\P{\\hat\\beta_1}$ is smaller than $\\text{se}\\P{\\tilde\\beta_1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "$\\bspace$Now we're gonna use the formula given in this chapter and obtian that:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tilde\\beta_1 &= \\ffrac{\\sum\\limits_{i=1}^{n} \\hat r_{i1}y_i} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\\\\\n",
    "&= \\ffrac{\\sum\\limits_{i=1}^{n} \\hat r_{i1}\\P{\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + u_i}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\\\\\n",
    "&= \\beta_0 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} +\\beta_1 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}x_{i1}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\beta_2 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i2}x_{i2}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}u_i} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bspace$Here $\\hat r_{i1}$ is the residual from a simple regression of $x_1$ on $x_2$, thus, we can simplify the above expression by making a analogy to SLR to:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tilde\\beta_1 &= \\beta_0 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\beta_1 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}x_{i1}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\beta_2 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i2}x_{i2}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}u_i} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\\\\\n",
    "&= \\beta_0 \\cdot 0 + \\beta_1 \\cdot 1 + \\beta_2 \\cdot 0 + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}u_i} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\bspace$Thus, we now take the expectation on both sides and obtain:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\EE{\\tilde\\beta_1} &= \\EE{\\beta_1 + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}u_i} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}}\\\\\n",
    "&= \\beta_1 + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} + \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i1}\\EE{u_i}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2} \\\\\n",
    "&= \\beta_1 + \\beta_3 \\cdot \\ffrac{\\sum\\limits_{i=1}^{n}\\hat r_{i3}x_{i3}} {\\sum\\limits_{i=1}^{n} \\hat r_{i1}^2}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "$\\P{i}$\n",
    "\n",
    "$\\bspace$Linearity is obvious cause this term can be also written like $\\tilde\\beta_1 = \\d{ \\sum_{i=1}^{n} \\P{\\ffrac{\\P{z_i - \\bar{z}}}{\\d{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}}}\\cdot y_i}$. Then for the unbiasedness, we have\n",
    "\n",
    "$$\\begin{align}\n",
    "\\tilde\\beta_1 &= \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}y_i}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}\\\\\n",
    "&= \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}\\P{\\beta_0 + \\beta_1 x_i + u_i}}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}\\\\\n",
    "&= \\beta_1 + \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}u_i}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\bspace$We then take expectaion on both sides and obtain:\n",
    "\n",
    "$$\\EE{\\tilde\\beta_1} = \\EE{\\beta_1 + \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}u_i}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}} = \\beta_1 + \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}\\EE{u_i}}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i} = \\beta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\P{\\text{ii}}$\n",
    "\n",
    "$$\\begin{align}\n",
    "\\Var{\\tilde{\\beta}_1} &= \\Var{\\beta_1 + \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}u_i}{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}} \\\\\n",
    "&= \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}^2\\Var{u_i}}{\\SB{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}^2}\\\\\n",
    "&= \\sigma^2\\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}^2}{\\SB{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}^2}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\P{\\text{iii}}$\n",
    "\n",
    "$\\bspace$First we write the expression for $\\Var{\\hat\\beta_1}$: $\\Var{\\hat\\beta_1} = \\ffrac{\\sigma^2} {\\SB{\\sum\\limits_{i=1}^{n}\\P{x_i - \\bar x}^2}^2}$. So that the inequality to prove is equivalent to:\n",
    "\n",
    "$$\\ffrac{1} {\\SB{\\sum\\limits_{i=1}^{n}\\P{x_i - \\bar x}^2}^2} \\leq \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}^2}{\\SB{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}x_i}^2} = \\ffrac{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}^2}{\\SB{\\sum\\limits_{i=1}^{n} \\P{z_i - \\bar{z}}\\P{x_i - \\bar{x}}}^2}$$\n",
    "\n",
    "And this is exactly what the hint shows! Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
