{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector\n",
    "It represents directed line segment in a space.  \n",
    "$\\odot$  \n",
    "No matter where they start, they only have directions and magnitudes. $\\square$\n",
    "\n",
    "## Expression\n",
    ">**e.g.**  \n",
    ">$n\\textrm{-dimensional}$ **column vector**  \n",
    ">$\\mathbf{u} = \n",
    "\\begin{bmatrix}\n",
    "u_1\\\\ \n",
    "u_2\\\\ \n",
    "\\dots\\\\ \n",
    "u_n\\\\\n",
    "\\end{bmatrix}$  \n",
    "> Here $u_1, u_2, \\dots, u_n$ are components of $\\mathbf{u}$\n",
    "\n",
    "The **transpose** of a column vector: **row vector**\n",
    ">**e.g.**  \n",
    ">$\\mathbf{u}^{\\mathrm{T}} = \\begin{bmatrix}\n",
    " u_1&u_2  &\\dots  &u_n \n",
    "\\end{bmatrix}$\n",
    "\n",
    "## Operation\n",
    "Addition, subtraction, scalar product, inner product, norms.\n",
    "### Inner product\n",
    "For $\\mathbf{u}$ and $\\mathbf{v}$, their inner product is:  \n",
    "$$\\left( \\mathbf{u}, \\mathbf{v} \\right) = \\begin{bmatrix}\n",
    "u_1\\\\ \n",
    "u_2\\\\ \n",
    "\\cdots\\\\ \n",
    "u_n\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "v_1\\\\ \n",
    "v_2\\\\ \n",
    "\\cdots\\\\ \n",
    "v_n\n",
    "\\end{bmatrix}\n",
    " = \\sum _{i=1} ^n u_i v_i$$\n",
    "\n",
    "### Norm\n",
    "For $\\mathbf{u}$ its euclidian length is:  \n",
    "$$\\sqrt{ \\left[ \\mathbf{u}, \\mathbf{u} \\right] } = \\sqrt{ u_1^2 + u_2^2 + \\cdots + u_n^2 } \\hat{=} \\left\\| \\mathbf{u} \\right\\|$$\n",
    "\n",
    "Then, the $p\\textrm{-norm}$ of $\\left\\| \\mathbf{u} \\right\\|$:  \n",
    "$$\\left\\| \\mathbf{u} \\right\\|_p = \\left( \\sum _{i=1} ^n \\left| u_i \\right| ^p \\right)^{1/p}$$  \n",
    "$p$ is a positive integer. And the default number is $2$ is no subscript.\n",
    "\n",
    "And if $p = \\infty$, then:  \n",
    "$$\\infty \\textrm{-norm}:\\; \\left\\| \\mathbf{u} \\right\\|_{\\infty} = \\underset{1 \\leq i \\leq n}{max} \\left| u_i \\right|$$\n",
    "$\\dagger$  \n",
    "用夹逼定理可以证明\n",
    "\n",
    "### Angle\n",
    "The angle $\\theta$ between $\\mathbf{u}$ and $\\mathbf{v}$:  \n",
    "$$\\cos \\theta = \\frac{\\left( \\mathbf{u}, \\mathbf{v} \\right)} {\\left\\| \\mathbf{u} \\right\\| \\left\\| \\mathbf{v} \\right\\|}$$\n",
    "$\\dagger$  \n",
    "$\\left \\| \\mathbf{c} \\right \\| = \\left \\| \\mathbf{a} - \\mathbf{b} \\right \\|$, 用余弦定理可以证明\n",
    "\n",
    "Two vectors are **orthogonal** if $\\theta = \\pi/2$. And this is equivalent to $\\left( \\mathbf{u}, \\mathbf{v} \\right) = 0$. Two vectors are **parallel** if $\\theta = 0$ or $\\pi$. $\\pi$ for the opposite direction.\n",
    "\n",
    "A set of vectors are orthogonal if any of two vectors in the set is orthogonal.\n",
    "\n",
    "And if all the vectors have length $1$, then they are a set of orthonormal vectors. And for those vectors with length $1$, they are **unit vectors**.\n",
    "\n",
    "### Linear Dependency\n",
    "A group of vectors: $\\mathbf{u}_1, \\dots, \\mathbf{u}_n$, are linear independent if the only scalars $k_1, \\dots, k_n$ for\n",
    "$$\\sum _{i=1} ^{n} k_i \\mathbf{u}_i = 0$$\n",
    "are $k_1 = \\cdots = k_n = 0$\n",
    ">**i.e.**\n",
    ">if $\\mathbf{u}_1, \\dots, \\mathbf{u}_n$ are linearly indepedent, then none of them can be represented by a linear combination of the others.\n",
    "\n",
    "$\\odot$\n",
    "If $\\mathbf{u}_1, \\dots, \\mathbf{u}_n$ are a set of nonzero orthogonal vectors, they must be linearly independent. $\\square$\n",
    "\n",
    "# Space\n",
    "## Def\n",
    "A vector space is a set of vectors which is a closed set under the addition, subtraction, and scalar multiplication.\n",
    ">**e.g.**\n",
    ">$\\mathbb{R}^n$ is a space which is the set of all $n\\mathrm{-dimensional}$ real column (or row) vectors.\n",
    "\n",
    "$\\odot$  \n",
    "Normally a space contains infinite number of vectors unless it contains only $\\vec{0}$.$\\square$\n",
    "\n",
    "## Spanning space\n",
    "The **spanning space** for $\\mathbf{u}_1, \\dots, \\mathbf{u}_n$, denoted as\n",
    "$\\left \\langle \\mathbf{u}_1, \\dots, \\mathbf{u}_n \\right \\rangle$, is all the linear combination of these vectors:  \n",
    "$$k_1 \\mathbf{u}_1 + k_2 \\mathbf{u}_2 + \\cdots + k_n \\mathbf{u}_n$$\n",
    "Here $k_1, k_2, \\dots k_n$ are any real numbers.\n",
    "\n",
    "## Dimension\n",
    "Given a space, if some vectors, say, $\\mathbf{u}_1, \\dots, \\mathbf{u}_r$, are linearly independent, and any other vector in that space can be represented as a linear combination of these $r$ vectors, then $\\mathbf{u}_1, \\dots, \\mathbf{u}_r$ form a **basis** of this space. The dimension of this space is $r$.  \n",
    "$\\dagger$  \n",
    "无论一开始怎么取，最后一定会加到$r$个的，一个不能少，一个多不了。\n",
    "\n",
    "**unit coordinate  vectors**:  \n",
    "$$\\mathbf{e}_1 = \\begin{bmatrix}\n",
    "1\\\\ \n",
    "0\\\\ \n",
    "\\cdots\\\\ \n",
    "0\n",
    "\\end{bmatrix},\n",
    "\\mathbf{e}_2 = \\begin{bmatrix}\n",
    "0\\\\ \n",
    "1\\\\ \n",
    "\\cdots\\\\ \n",
    "0\n",
    "\\end{bmatrix},\n",
    "\\cdots,\n",
    "\\mathbf{e}_n = \\begin{bmatrix}\n",
    "0\\\\ \n",
    "0\\\\ \n",
    "\\cdots\\\\ \n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    ">**e.g.**  \n",
    ">then using the components of $\\mathbf{u}$, $i.e.$, $u_1, u_2, \\dots, u_n$, we can represent $\\mathbf{u}$ as:\n",
    ">$$\\sum _{i=1} ^n u_i \\mathbf{e}_i$$\n",
    "\n",
    "Thus we call this set of orthonormal vectors in $\\mathbb{R}^n$ an **orthonormal basis正交基**.\n",
    "\n",
    "$\\odot$\n",
    "The dimension of the span space, $\\left \\langle \\mathbf{u}_1, \\dots, \\mathbf{u}_n \\right \\rangle$, is the most number of independent vectors within, not the number of components a vector has.$\\square$\n",
    "\n",
    "## Others\n",
    "For a polynomial:  \n",
    "$$p_n \\left( x \\right) = k_1 x^0 + k_2 x^1 + \\cdots + k_n x^{n-1}$$\n",
    "\n",
    "Here $k_1, k_2, \\dots , k_n$ are real coefficients.\n",
    "Then **monomials单项式** $x^0, x^1, \\dots, x^{n-1}$ is the basis of space $P_n$ that is all possible polynomials of degree less or equal $n-1$.\n",
    "\n",
    "$\\dagger$  \n",
    "*Span* contains *Basis* contains *Orthogonal basis* contains *orthonormal basis*.\n",
    "\n",
    "# Matrix\n",
    "## Expression\n",
    "$A \\in \\mathbb{R}^{m \\times n}$, represents a real $m \\times n$ matrix with $m$ rows and $n$ columns. Here $\\mathbb{R}^{m \\times n}$ denotes the space of all matrix with same shape. And $a_{i,j}$ denotes the entry at $i \\textrm{-th}$ row and $j \\textrm{-th}$ column.\n",
    "\n",
    "Other ways to represent $A$:\n",
    "$$A = \\left( a_{i,j} \\right)_{m \\times n} = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\ \n",
    "a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \n",
    " &  & \\cdots & \\\\ \n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{a}^c_1,& \\mathbf{a}^c_2,& \\dots,& \\mathbf{a}^c_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{z}^r_1,\\\\\n",
    "\\mathbf{z}^r_2,\\\\\n",
    "\\cdots,\\\\\n",
    "\\mathbf{z}^r_m\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$\\dagger$  \n",
    "以后$A$的列向量就是$\\mathbf{a}^c_j, 1 \\leq j \\leq n$，行向量就是$\\mathbf{a}^r_i, 1 \\leq i \\leq m$。\n",
    "\n",
    "## Operations\n",
    "Addition, subtraction, and scalar multiplication on matrices are done **entry-wise**. And the **transpose**:\n",
    "$$A^{\\mathrm{T}} = \\left( a_{ji} \\right)_{n \\times m}$$\n",
    "\n",
    "About **product**:\n",
    "$$A_{m \\times n} = B_{m \\times l} \\times C_{l \\times n}$$\n",
    "Here $a_{ij} = \\mathbf{b}^r_i \\cdot \\mathbf{c}^c_j$, and $\\mathbf{b}^r_i$ is the $i\\textrm{-th}$ **r**ow vector of matrix $B$ and $\\mathbf{c}^c_j$ is the $j\\textrm{-th}$ **c**olumn vector of matrix $C$.\n",
    "\n",
    ">**e.g.**  \n",
    "> For the inner product:  \n",
    "> $\\left( \\mathbf{u}, \\mathbf{v} \\right) = \\mathbf{u}^{\\mathrm{T}} \\mathbf{v}$  \n",
    "> For the product of a matrix and a vector:  \n",
    "> $A\\mathbf{x}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{a}^c_1 &  \\mathbf{a}^c_2 & \\dots & \\mathbf{a}^c_n\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\  x_2 \\\\ \\dots \\\\ x_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sum _{i=1} ^n x_i \\mathbf{a}_i\n",
    "= \\mathbf{b}$\n",
    ">  \n",
    "> Here $\\mathbf{b}$ is a $m\\textrm{-dimensinal}$ column vector.\n",
    "\n",
    "## Other Characteristics\n",
    "- *Square matrix*, if $m=n$.\n",
    "- *Symmetric matrix*, if $A = A^{\\mathrm{T}}$\n",
    "- *Diagonal matrix*, 对角矩阵，仅对角元素非零\n",
    "- *Identity matrix*, 单位矩阵\n",
    "- *Upper/Lower triangular matrix*, 上/下三角矩阵\n",
    "- *Tridiagonal matrix*, 三对角阵，$\\dagger$这不重要\n",
    "\n",
    "**Column space**: The space spanned by the column vectors of $A_{m \\times n}$ is called its column space (or we call it **range**). (**Row space** 差不多)  \n",
    "Since $A$ has $m$ rows meaning that its column vectors all got $m$ components. Thus,  \n",
    "$\\odot$\n",
    "The range of $A$ is a subspace of $\\mathbb{R}^m$.$\\square$\n",
    "\n",
    "$\\dagger$  \n",
    "Range似乎只能指列向量生成空间？问下老师。然后就是$A$假如是$m$行，那么$A$的Range是$\\mathbb{R}^m$的子空间，没说Range是$m$维空间！\n",
    "\n",
    "$\\odot$\n",
    "Actually, $\\forall A$, the dimension of its column space **equals** to that of its row space, namely, the **rank** of $A$. $\\square$\n",
    "\n",
    "If $rank \\left( A \\right) = \\min \\left\\{ m,n \\right\\}$ then we say $A$ is **full rank**.\n",
    "***\n",
    "Let $A$ now be an $m \\times m$ square matrix. Then if $rank(A)=m$, then we say it is **nonsingular** (**invertible**) matrix.  \n",
    "$\\dagger$  \n",
    "满秩方阵就是非奇异矩阵，或者说不可逆\n",
    "\n",
    "$\\odot$\n",
    "If $A$ is nonsingular, then there exists a matrix $A^{-1}$, such that $AA^{-1} = A^{-1}A = I$. Here $A^{-1}$ is the **inverse** of $A$. $\\square$\n",
    "\n",
    "And if a square matrix $Q$ satisfies $Q^{\\mathrm{T}} = Q^{-1}$, $i.e.$, $QQ^{\\mathrm{T}} = Q^{\\mathrm{T}} Q = I$, $Q$ is an **orthogonal matrix正交矩阵**.\n",
    "\n",
    "$\\odot$\n",
    "$\\forall Q$ that is orthogonal, its column vectors (also its row vectors) form an orthonormal basis of the space $\\mathbb{R}^m$. Besides, they preserve the inner product, $i.e.$, $(Q\\mathbf{u}, Q\\mathbf{v}) = (Q\\mathbf{u})^{\\mathrm{T}}(Q\\mathbf{v}) = \\mathbf{u}^{\\mathrm{T}} Q^{\\mathrm{T}} Q\\mathbf{v} = \\mathbf{u}^{\\mathrm{T}}\\mathbf{v} = (\\mathbf{u},\\mathbf{v})$. Therefore, orthogonal matrices also preserves the length of a vector, and the angles between two vectors. $\\square$\n",
    "\n",
    "> **e.g.**  \n",
    "> A rotation matrix: $Q = \\begin{bmatrix}\n",
    "\\cos \\theta & - \\sin \\theta \\\\ \n",
    "\\sin \\theta & \\cos \\theta\n",
    "\\end{bmatrix}$.  \n",
    "> Clerely, we have $Q^{\\mathrm{T}} = Q^{-1}$.  \n",
    "> And $\\forall \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} r \\cos \\alpha \\\\ r \\sin \\alpha \\end{bmatrix}$, we have:  \n",
    "> $$Q \\mathbf{x} = \\begin{bmatrix}\n",
    "\\cos \\theta & - \\sin \\theta \\\\ \n",
    "\\sin \\theta & \\cos \\theta\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix} r \\cos \\alpha \\\\ r \\sin \\alpha \\end{bmatrix} = \\begin{bmatrix} r \\cos (\\alpha + \\theta) \\\\ r \\sin (\\alpha + \\theta) \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "***\n",
    "We call the set of vectors $\\mathbf{x}$, satisfying $A\\mathbf{x} = 0$, the **null space** of $A$, denoted as $null(A)$.  \n",
    "$\\dagger$  \n",
    "就是这个方程的解集是对应矩阵的零空间。\n",
    "\n",
    "$\\odot$\n",
    "$\\forall A \\in \\mathbb{R}^{m \\times n}, rank(A) + dim(null(A)) = n$. $\\square$  \n",
    "$\\dagger$  \n",
    "闲着没事给个证明提示\n",
    "$$A\\mathbf{x} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{a}^c_1 & \n",
    "\\mathbf{a}^c_2 & \n",
    "\\dots & \n",
    "\\mathbf{a}^c_n\n",
    "\\end{bmatrix} \\cdot \\mathbf{x} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{a}^c_1 \\cdot \\mathbf{x} & \n",
    "\\mathbf{a}^c_2 \\cdot \\mathbf{x} &\n",
    "\\dots &\n",
    "\\mathbf{a}^c_n \\cdot \\mathbf{x}\n",
    "\\end{bmatrix} = 0 \\Rightarrow \\mathbf{a^r}_i \\cdot \\mathbf{x} = 0, i.e. \\mathbf{a^r}_i \\perp x$$\n",
    "\n",
    "# Matrix norms\n",
    "$\\odot$\n",
    "Given $A \\in \\mathbb{R}^{m \\times n}$, $A$ can be seen as a map from $\\mathbb{R}^n$ to $\\mathbb{R}^m$. $\\square$  \n",
    "Then the **norm** of $A$:\n",
    "$$\\| A \\| = \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac {\\| A \\mathbf{x} \\|} {\\| \\mathbf{x} \\|} = \\underset{\\| \\mathbf{x} \\| = 1}{\\max} \\| A \\mathbf{x} \\|$$\n",
    "\n",
    "$\\odot$\n",
    "$$\\| A \\|_1 = \\underset{ 1 \\leq j \\leq n}{\\max} \\| \\mathbf{a}^c_j \\|_1.$$  \n",
    "Which ~~is the maximum of column sum.~~\n",
    "$$\\| A \\|_{\\infty} = \\underset{ 1 \\leq i \\leq m}{\\max} \\| \\mathbf{a}^r_i \\|_1.$$  \n",
    "Which ~~is the maximum of row sum.~~  \n",
    "$\\dagger$  \n",
    "这里其实不是直接的和，事实上是一阶范数，不是元素绝对值的和。所以矩阵的一阶范数是the maximum absolute column sum of the matrix。无穷范数是the maximum absolute row sum of the matrix。  \n",
    "$i.e.,$\n",
    "$$\\|A\\|_{1}=\\max _{1\\leq j\\leq n}\\sum _{i=1}^{m}|a_{ij}|, \\|A\\|_{\\infty }=\\max _{1\\leq i\\leq m}\\sum _{j=1}^{n}|a_{ij}|$$\n",
    "\n",
    "$Prove$  \n",
    "$\\| A \\|_1  \\leq \\underset{ 1 \\leq j \\leq n}{\\max} \\| \\mathbf{a}^c_j \\|_1$:\n",
    "$$\\begin{align*}\n",
    "\\| A \\|_1 & =  \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac {\\| A \\mathbf{x} \\|_1} {\\| \\mathbf{x} \\|_1} = \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac {\\| \\sum _{i=1} ^n x_i \\mathbf{a}^c_i \\|_1} {\\| \\mathbf{x} \\|_1} \\\\\n",
    "& \\leq \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac {\\sum _{i=1} ^n |x_i| \\cdot \\|\\mathbf{a}^c_i \\|_1} {\\| \\mathbf{x} \\|_1} \\\\\n",
    "& \\leq \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac { \\left( \\sum _{i=1} ^n |x_i| \\right ) \\cdot \\underset{1 \\leq j \\leq n}{\\max} \\|\\mathbf{a}^c_i \\|_1} {\\| \\mathbf{x} \\|_1} \\\\\n",
    "& = \\underset{ 1 \\leq j \\leq n}{\\max} \\| \\mathbf{a}^c_j \\|_1\n",
    "\\end{align*} $$\n",
    "$\\| A \\|_1  \\geq \\underset{ 1 \\leq j \\leq n}{\\max} \\| \\mathbf{a}^c_j \\|_1$:  \n",
    "$$\\forall j = 1,2, \\dots, n, \\| A \\|_1  =  \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac {\\| A \\mathbf{x} \\|_1} {\\| \\mathbf{x} \\|_1} \\geq \\frac {\\| A \\mathbf{e}_j \\|_1} {\\| \\mathbf{e_j} \\|_1} = \\| \\mathbf{a} \\|^c_j$$\n",
    "$i.e., \\| A \\|_1  \\geq \\underset{ 1 \\leq j \\leq n}{\\max} \\| \\mathbf{a}^c_j \\|_1$\n",
    "$\\square$\n",
    "\n",
    "$\\dagger$\n",
    "无穷范数会证了。看作业第一题。\n",
    "\n",
    "$\\odot$\n",
    "$$\\begin{align*}\n",
    "\\|A^{-1}\\| &= \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\frac{\\|A^{-1} \\mathbf{x}\\|} {\\| \\mathbf{x}\\|} = \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\max} \\left( \\frac{\\| \\mathbf{x}\\|} {\\|A^{-1} \\mathbf{x}\\|} \\right)^{-1} = \\left( \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\min} \\frac{\\| \\mathbf{x}\\|} {\\|A^{-1} \\mathbf{x}\\|} \\right)^{-1}\\\\\n",
    "&= \\left( \\underset{\\mathbf{x} \\neq \\mathbf{0}}{\\min} \\frac{\\|A \\mathbf{x}\\|} {\\| \\mathbf{x}\\|} \\right)^{-1}\n",
    "\\end{align*} $$ \n",
    "$i.e.,$  \n",
    "the norm of $A^{-1}$ is the inverse of the minimum amplification factor of vectors under the matrix $A$.$\\square$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "252px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
