{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allenâ€“Cahn Equation with Plain Gradient Descent and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "\n",
    "tf.reset_default_graph()\n",
    "start_time = time.time()\n",
    "\n",
    "name = 'AllenCahn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tersorflow Version: 1.13.1\n",
      "numpy Version: 1.16.4\n"
     ]
    }
   ],
   "source": [
    "print('tersorflow Version: '+tf.__version__)\n",
    "print('numpy Version: '+np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting of the problem\n",
    "d= 20\n",
    "T = 0.3\n",
    "Xi = np.zeros([1,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup of algorithm and implementation\n",
    "N = 20\n",
    "h = T/N\n",
    "sqrth = np.sqrt(h)\n",
    "n_maxstep = 10000\n",
    "batch_size = 1\n",
    "gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net architectures\n",
    "n_neuronForGamma = [d, d, d, d**2]\n",
    "n_neuronForA = [d, d, d, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (adapted) right hand side of the pde\n",
    "def f0(t,X,Y,Z,Gamma):\n",
    "    return -Y+tf.pow(Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminal condition\n",
    "def g(X):\n",
    "    return 1/(1 + 0.2*tf.reduce_sum(tf.square(X),1, keep_dims=True))*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for constructing the neural net(s)\n",
    "def _one_time_net(x, name, isgamma = False):\n",
    "    #with tf.variable_scope(name):\n",
    "    with tf.variable_scope(name):\n",
    "        layer1 = _one_layer(x, (1-isgamma)*n_neuronForA[1]+isgamma*n_neuronForGamma[1],\n",
    "                            name = 'layer1')\n",
    "        layer2 = _one_layer(layer1, (1-isgamma)*n_neuronForA[2]+isgamma*n_neuronForGamma[2],\n",
    "                            name = 'layer2')\n",
    "        z = _one_layer(layer2, (1-isgamma)*n_neuronForA[3]+isgamma*n_neuronForGamma[3], activation_fn=None,\n",
    "                       name = 'final')\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_layer(input_, output_size, activation_fn=tf.nn.relu,stddev=5.0, name='linear'):\n",
    "    #with tf.variable_scope(name):\n",
    "    with tf.variable_scope(name):\n",
    "        shape = input_.get_shape().as_list()\n",
    "        w = tf.get_variable('Matrix', [shape[1], output_size],\n",
    "                            tf.float64,\n",
    "                            tf.random_normal_initializer(\n",
    "                                stddev=stddev/np.sqrt(shape[1]+output_size)))\n",
    "        b = tf.get_variable('Bias', [1,output_size], tf.float64,\n",
    "                            tf.constant_initializer(0.0))\n",
    "        hidden = tf.matmul(input_, w) + b\n",
    "        if activation_fn:\n",
    "            return activation_fn(hidden)\n",
    "        else:\n",
    "            return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-10-89528d9ddf08>:30: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From E:\\Programs\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "step:  0  loss:  0.346438874602864  Y0:  [-0.55089559]  learning rate:  0.001\n",
      "step:  2000  loss:  0.011011010964087868  Y0:  [0.22266506]  learning rate:  0.001\n",
      "step:  4000  loss:  9.872989514596177e-05  Y0:  [0.3003935]  learning rate:  0.001\n",
      "step:  6000  loss:  0.0021802121209678065  Y0:  [0.31150471]  learning rate:  0.001\n",
      "step:  8000  loss:  0.0030028340938099973  Y0:  [0.31509093]  learning rate:  0.001\n",
      "step:  10000  loss:  0.00015095087330873214  Y0:  [0.30988549]  learning rate:  0.0\n",
      "running time:  44.63525938987732\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # background dynamics\n",
    "    dW = tf.random_normal(shape=[batch_size, d], stddev = sqrth, dtype=tf.float64)\n",
    "    # initial values of the stochastic processes\n",
    "    X = tf.Variable(np.ones([batch_size, d]) * Xi,\n",
    "                    dtype = tf.float64,\n",
    "                    name='X',\n",
    "                    trainable=False)\n",
    "    Y0 = tf.Variable(tf.random_uniform([1], minval = -1, maxval = 1, dtype=tf.float64),\n",
    "                     name='Y0')\n",
    "    Z0 = tf.Variable(tf.random_uniform([1,d], minval = -.1, maxval = .1, dtype=tf.float64),\n",
    "                     name='Z0')\n",
    "    Gamma0 = tf.Variable(tf.random_uniform([d, d], minval = -.1, maxval = .1, dtype=tf.float64),\n",
    "                         name='Gamma0')\n",
    "    A0 = tf.Variable(tf.random_uniform([1,d], minval = -.1, maxval = .1, dtype=tf.float64),\n",
    "                     name='A0')\n",
    "    allones = tf.ones(shape=[batch_size, 1],\n",
    "                      dtype=tf.float64,\n",
    "                      name='MatrixOfOnes')\n",
    "    Y = allones * Y0\n",
    "    Z = tf.matmul(allones,Z0)\n",
    "    Gamma = tf.multiply(tf.ones([batch_size, d, d],\n",
    "                                dtype = tf.float64), \n",
    "                        Gamma0)\n",
    "    A = tf.matmul(allones,A0)\n",
    "\n",
    "    # forward discretization\n",
    "    with tf.variable_scope('forward'):\n",
    "        for i in range(N-1):\n",
    "            Y = Y + f0(i*h,X,Y,Z,Gamma)*h + tf.reduce_sum(dW*Z, 1, keep_dims=True)\n",
    "            Z = Z + A * h + tf.squeeze(\n",
    "                tf.matmul(Gamma, tf.expand_dims(dW, -1))\n",
    "            )\n",
    "            Gamma = tf.reshape(\n",
    "                _one_time_net(X, name=str(i)+'Gamma', isgamma=True)/d**2,\n",
    "                [batch_size, d, d]\n",
    "            )\n",
    "            if i!=N-1:\n",
    "                A = _one_time_net(X, name=str(i)+'A')/d\n",
    "            X = X + dW\n",
    "            dW = tf.random_normal(\n",
    "                shape=[batch_size, d],\n",
    "                stddev = sqrth,\n",
    "                dtype=tf.float64\n",
    "            )\n",
    "        Y = Y + f0( (N-1)*h , X,Y,Z,Gamma)*h + tf.reduce_sum(dW*Z, 1, keep_dims=True)\n",
    "        X = X + dW\n",
    "        loss_function = tf.reduce_mean(tf.square(Y-g(X)))\n",
    "\n",
    "    # specifying the optimizer\n",
    "    global_step = tf.get_variable(\n",
    "        'global_step', [],\n",
    "        initializer=tf.constant_initializer(0),\n",
    "        trainable=False, dtype=tf.int32\n",
    "    )\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        gamma, global_step,\n",
    "        decay_steps = 10000, decay_rate = 0.0, staircase = True\n",
    "    )\n",
    "    trainable_variables = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss_function, trainable_variables)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    apply_op = optimizer.apply_gradients(\n",
    "        zip(grads, trainable_variables),\n",
    "        global_step=global_step, name='train_step'\n",
    "    )\n",
    "\n",
    "    with tf.control_dependencies([apply_op]):\n",
    "        train_op_2 = tf.identity(loss_function, name='train_op2')\n",
    "\n",
    "    # to save history\n",
    "    learning_rates = []\n",
    "    y0_values = []\n",
    "    losses = []\n",
    "    running_time = []\n",
    "    steps = []\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    try:\n",
    "        # the actual training loop\n",
    "        for _ in range(n_maxstep + 1):\n",
    "            y0_value, step = sess.run([Y0, global_step])\n",
    "            currentLoss, currentLearningRate = sess.run(\n",
    "                [train_op_2, learning_rate]\n",
    "            )\n",
    "\n",
    "            learning_rates.append(currentLearningRate)\n",
    "            losses.append(currentLoss)\n",
    "            y0_values.append(y0_value)\n",
    "            running_time.append(time.time()-start_time)\n",
    "            steps.append(step)\n",
    "\n",
    "            if step % 2000 == 0:\n",
    "                print(\"step: \", step,\n",
    "                      \" loss: \", currentLoss,\n",
    "                      \" Y0: \" , y0_value,\n",
    "                      \" learning rate: \", currentLearningRate)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"running time: \", end_time-start_time)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nmanually disengaged\")\n",
    "# writing results to a csv file\n",
    "output = np.zeros((len(y0_values),5))\n",
    "output[:,0] = steps\n",
    "output[:,1] = losses\n",
    "output[:,2] = y0_values\n",
    "output[:,3] = learning_rates\n",
    "output[:,4] = running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = str(name) + \"_d\" + str(d) + \"_\" + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')+ \".csv\"\n",
    "np.savetxt(\n",
    "    fname,\n",
    "    output,\n",
    "    delimiter = \",\",\n",
    "    header = 'step, loss function, Y0, learning rate, running time',\n",
    "    comments=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0=pd.read_csv('AllenCahn_d20_2020-05-01-07-47-26.csv')\n",
    "sample1=pd.read_csv('AllenCahn_d20_2020-05-01-13-16-54.csv')\n",
    "sample2=pd.read_csv('AllenCahn_d20_2020-05-01-13-18-06.csv')\n",
    "sample3=pd.read_csv('AllenCahn_d20_2020-05-01-13-20-23.csv')\n",
    "sample4=pd.read_csv('AllenCahn_d20_2020-05-01-13-23-21.csv')\n",
    "sample5=pd.read_csv('AllenCahn_d20_2020-05-01-13-26-07.csv')\n",
    "sample6=pd.read_csv('AllenCahn_d20_2020-05-01-13-34-14.csv')\n",
    "sample7=pd.read_csv('AllenCahn_d20_2020-05-01-14-07-12.csv')\n",
    "sample8=pd.read_csv('AllenCahn_d20_2020-05-01-14-11-43.csv')\n",
    "sample9=pd.read_csv('AllenCahn_d20_2020-05-01-14-13-21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "step0df=pd.DataFrame()\n",
    "for i in range(10):\n",
    "    exec('temp_row=sample'+str(i)+'.iloc[[0],:]')\n",
    "    step0df=step0df.append(temp_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>loss function</th>\n",
       "      <th>Y0</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>running time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166497</td>\n",
       "      <td>0.355385</td>\n",
       "      <td>0.001</td>\n",
       "      <td>13.899477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125224</td>\n",
       "      <td>0.520581</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.005932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step   loss function        Y0   learning rate   running time\n",
       "mean   0.0        0.166497  0.355385           0.001      13.899477\n",
       "std    0.0        0.125224  0.520581           0.000      12.005932"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step0df.apply([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(10,5)\n",
    "ax = fig.add_subplot(111)\n",
    "A = ax.semilogy(steps[0:5000],losses[0:5000])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
